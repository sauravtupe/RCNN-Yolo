{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1 How do you load and run inference on a custom image using the YOLOv8 model (labeled as YOLOv9)"
      ],
      "metadata": {
        "id": "5gYng3wGJW06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw5cELjmIijx",
        "outputId": "0926f07a-6f5d-4df3-9d61-3594e702d924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.151-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.151-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.151 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8 model (YOLOv9 label might refer to this)\n",
        "model = YOLO('yolov8n.pt')  # 'yolov8n.pt' is the nano model, replace with your custom weights path if any\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB37ktklIrrk",
        "outputId": "3f09a430-715e-4d73-92ca-38513a93c95d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 77.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # Load model\n",
        "results = model('your_image.jpg')  # Run inference\n",
        "results.show()  # Display predictions\n",
        "results.save()  # Save output images with predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "cGk2ac5bJLVz",
        "outputId": "ad4f83b9-1951-45e5-ab04-f10bae842681"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "your_image.jpg does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6348ca344ac8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8n.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'your_image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Display predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save output images with predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_imgsz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, batch, vid_stride, buffer, channels)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImagesAndVideos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch, vid_stride, channels)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Define files as images or videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: your_image.jpg does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 How do you load the Faster RCNN model with a ResNet50 backbone and print its architecture6"
      ],
      "metadata": {
        "id": "iSmipA1TJurt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Load the Faster R-CNN model with ResNet-50 backbone, pretrained on COCO\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1rHcY-_JTkb",
        "outputId": "ae57a0fd-4633-4cad-8ec3-c80774ae88e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FasterRCNN(\n",
            "  (transform): GeneralizedRCNNTransform(\n",
            "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
            "  )\n",
            "  (backbone): BackboneWithFPN(\n",
            "    (body): IntermediateLayerGetter(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (fpn): FeaturePyramidNetwork(\n",
            "      (inner_blocks): ModuleList(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (layer_blocks): ModuleList(\n",
            "        (0-3): 4 x Conv2dNormActivation(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (extra_blocks): LastLevelMaxPool()\n",
            "    )\n",
            "  )\n",
            "  (rpn): RegionProposalNetwork(\n",
            "    (anchor_generator): AnchorGenerator()\n",
            "    (head): RPNHead(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): RoIHeads(\n",
            "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
            "    (box_head): TwoMLPHead(\n",
            "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNPredictor(\n",
            "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3  How do you perform inference on an online image using the Faster RCNN model and print the predictions6\n"
      ],
      "metadata": {
        "id": "3_uum0DFKBDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision requests pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JzC1oGoJ-Qw",
        "outputId": "801ddfe6-06ae-47c1-d5e6-9ee5f66bf966"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Load the pretrained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# URL of the online image\n",
        "url = \"https://example.com/your-image.jpg\"  # Replace with your image URL\n",
        "\n",
        "# Load the image from URL\n",
        "response = requests.get(url)\n",
        "image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "# Define the transformations: convert image to tensor\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "img_tensor = transform(image)\n",
        "\n",
        "# Run inference (wrap input in a list as model expects a batch)\n",
        "with torch.no_grad():\n",
        "    predictions = model([img_tensor])\n",
        "\n",
        "# Print predictions\n",
        "print(predictions)\n",
        "\n",
        "# Optional: to print detected classes and boxes with scores above threshold\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
        "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
        "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog',\n",
        "    'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "pred = predictions[0]\n",
        "\n",
        "# Set a confidence threshold\n",
        "threshold = 0.5\n",
        "\n",
        "for idx in range(len(pred['boxes'])):\n",
        "    score = pred['scores'][idx].item()\n",
        "    if score > threshold:\n",
        "        label = COCO_INSTANCE_CATEGORY_NAMES[pred['labels'][idx]]\n",
        "        box = pred['boxes'][idx].tolist()\n",
        "        print(f\"Label: {label}, Confidence: {score:.2f}, Box coordinates: {box}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "5MdsuLDTKI07",
        "outputId": "7394c934-356e-4ba9-ed70-8a013b84886d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x7943858bfba0>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-454476b9285e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load the image from URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Define the transformations: convert image to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3570\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3572\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7943858bfba0>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4  How do you load an image and perform inference using YOLOv9, then display the detected objects with\n",
        "bounding boxes and class labels"
      ],
      "metadata": {
        "id": "3oue7Em6KQGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load the YOLOv9 model (replace with your custom weights if needed)\n",
        "model = YOLO('yolov8n.pt')  # or 'yolov9.pt' if you have that file\n",
        "\n",
        "# Load your image path\n",
        "image_path = 'path/to/your/image.jpg'\n",
        "\n",
        "# Run inference\n",
        "results = model(image_path)\n",
        "\n",
        "# results.show()  # To open a window and display the image with detections (if GUI supported)\n",
        "\n",
        "# Alternatively, visualize detections manually using OpenCV:\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Loop over detections and draw bounding boxes + labels\n",
        "for result in results:\n",
        "    boxes = result.boxes\n",
        "    for box in boxes:\n",
        "        # Get coordinates\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        conf = box.conf[0].item()\n",
        "        cls_id = int(box.cls[0].item())\n",
        "        label = model.names[cls_id]\n",
        "\n",
        "        # Draw rectangle\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Put label text above rectangle\n",
        "        cv2.putText(image, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "# Show image with detections\n",
        "cv2.imshow('YOLOv9 Detection', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "FJiXWdBUKL-V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 How do you display bounding boxes for the detected objects in an image using Faster RCNN6"
      ],
      "metadata": {
        "id": "5Jn1gUJMKc5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Load model and set to eval mode\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load and preprocess image\n",
        "url = \"https://example.com/your-image.jpg\"  # Replace with your image URL\n",
        "response = requests.get(url)\n",
        "image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "img_tensor = transform(image)\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    outputs = model([img_tensor])\n",
        "\n",
        "# COCO dataset class names\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
        "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
        "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog',\n",
        "    'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "output = outputs[0]\n",
        "\n",
        "# Set confidence threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Prepare to draw\n",
        "draw = ImageDraw.Draw(image)\n",
        "font = ImageFont.load_default()\n",
        "\n",
        "# Draw boxes and labels\n",
        "for box, score, label_idx in zip(output['boxes'], output['scores'], output['labels']):\n",
        "    if score >= threshold:\n",
        "        x1, y1, x2, y2 = box\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        label = COCO_INSTANCE_CATEGORY_NAMES[label_idx]\n",
        "        draw.rectangle([(x1, y1), (x2, y2)], outline='red', width=3)\n",
        "        draw.text((x1, y1 - 10), f\"{label}: {score:.2f}\", fill='red', font=font)\n",
        "\n",
        "# Show the image\n",
        "image.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "xSLEWMC5KWdy",
        "outputId": "e176b759-1994-4189-b042-739b3989f114"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x794391f8fab0>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-91bdc4e10ec8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://example.com/your-image.jpg\"\u001b[0m  \u001b[0;31m# Replace with your image URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3570\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3572\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x794391f8fab0>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6  How do you perform inference on a local image using Faster RCNN"
      ],
      "metadata": {
        "id": "rwVxASwrKlpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q33U4DnPKhBJ",
        "outputId": "2dca27e3-af03-4d1e-d90e-9264335553c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Load pretrained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# Load and preprocess local image\n",
        "image_path = 'path/to/your/local/image.jpg'\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "img_tensor = transform(image)\n",
        "\n",
        "# Run inference (model expects list of tensors)\n",
        "with torch.no_grad():\n",
        "    predictions = model([img_tensor])\n",
        "\n",
        "# Output is a list with dict per image; get first item\n",
        "pred = predictions[0]\n",
        "\n",
        "# Print predicted classes, boxes, and scores above a threshold\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
        "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
        "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog',\n",
        "    'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "for box, label, score in zip(pred['boxes'], pred['labels'], pred['scores']):\n",
        "    if score >= threshold:\n",
        "        print(f\"Detected {COCO_INSTANCE_CATEGORY_NAMES[label]} with confidence {score:.2f}\")\n",
        "        print(f\"Bounding box: {box.tolist()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "vW2IBc6uKt5R",
        "outputId": "2e11c87d-5200-4514-a86c-c3954aca23bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path/to/your/local/image.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b9a56ac53758>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load and preprocess local image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/your/local/image.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/your/local/image.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 How can you change the confidence threshold for YOLO object detection and filter out low-confidence\n",
        "predictions6"
      ],
      "metadata": {
        "id": "6Xl-riJiK34s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load model\n",
        "model = YOLO('yolov8n.pt')  # or your YOLOv9 weights\n",
        "\n",
        "# Run inference with confidence threshold set (e.g., 0.5)\n",
        "results = model('path/to/image.jpg', conf=0.5)  # conf parameter sets confidence threshold\n",
        "\n",
        "# Now results only contain predictions with confidence >= 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "pooEr84GKwLy",
        "outputId": "192a1a72-5275-4f36-e272-80b38ef38b68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "path/to/image.jpg does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d94ce6a3bd18>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Run inference with confidence threshold set (e.g., 0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/image.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# conf parameter sets confidence threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Now results only contain predictions with confidence >= 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_imgsz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, batch, vid_stride, buffer, channels)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImagesAndVideos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch, vid_stride, channels)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Define files as images or videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: path/to/image.jpg does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model('path/to/image.jpg')  # Run with default confidence\n",
        "\n",
        "# Filter boxes manually:\n",
        "filtered_boxes = []\n",
        "filtered_scores = []\n",
        "filtered_classes = []\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        conf = box.conf.item()\n",
        "        if conf >= 0.5:\n",
        "            filtered_boxes.append(box.xyxy)\n",
        "            filtered_scores.append(conf)\n",
        "            filtered_classes.append(box.cls)\n",
        "\n",
        "# Now filtered_* contain only high-confidence predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Zbka-6tdK8gQ",
        "outputId": "48a3297f-438d-4a3a-a42a-f47960662988"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "path/to/image.jpg does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4ad3b0aad8af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Run with default confidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Filter boxes manually:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiltered_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiltered_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_imgsz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, batch, vid_stride, buffer, channels)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImagesAndVideos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch, vid_stride, channels)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Define files as images or videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: path/to/image.jpg does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 How do you plot the training and validation loss curves for model evaluation"
      ],
      "metadata": {
        "id": "c9LitJ2lLC31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example lists of loss values recorded during training\n",
        "train_losses = [0.9, 0.7, 0.5, 0.4, 0.3]  # replace with your actual training losses per epoch\n",
        "val_losses = [1.0, 0.8, 0.6, 0.45, 0.35]  # replace with your actual validation losses per epoch\n",
        "\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n",
        "\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "5zAR0w54K-Qo",
        "outputId": "0fc60b45-cfe5-43d1-f665-21a1ffac1539"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHWCAYAAABkNgFvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlRVJREFUeJzs3XdUVNfax/HvmaGMSFERKYoNC2LBFhEVNVfsElsSe9coiVFjvFFvElvam5tmS+zGFhONGjVRUewoxI69ERQLYEcEpM68f8yVSAQFBA4wz2etWclszpnzm82gj4ddFIPBYEAIIYQQQogiSKN2ACGEEEIIIXJLilkhhBBCCFFkSTErhBBCCCGKLClmhRBCCCFEkSXFrBBCCCGEKLKkmBVCCCGEEEWWFLNCCCGEEKLIkmJWCCGEEEIUWVLMCiGEEEKIIkuKWSFEvhs8eDCVK1fO1bnTpk1DUZS8DVTIXL16FUVRWLZsWYFfW1EUpk2blv582bJlKIrC1atXX3hu5cqVGTx4cJ7meZnPihDCNEkxK4QJUxQlW4+9e/eqHdXkjRkzBkVRCAsLy/KYDz/8EEVROHXqVAEmy7nIyEimTZtGaGio2lHSPfkHxddff612FCFEDpmpHUAIoZ6VK1dmeL5ixQoCAwOfaa9Vq9ZLXWfRokXo9fpcnfvRRx8xadKkl7p+cdCvXz/mzJnD6tWrmTJlSqbH/Pzzz9StW5d69erl+joDBgygd+/eWFpa5vo1XiQyMpLp06dTuXJl6tevn+FrL/NZEUKYJilmhTBh/fv3z/D8zz//JDAw8Jn2f0pISMDKyirb1zE3N89VPgAzMzPMzOSPKi8vL6pVq8bPP/+caTEbEhLClStX+L//+7+Xuo5Wq0Wr1b7Ua7yMl/msCCFMkwwzEEI8V+vWralTpw7Hjh2jZcuWWFlZ8Z///AeATZs20blzZ1xcXLC0tMTNzY1PPvmEtLS0DK/xz3GQT/9Kd+HChbi5uWFpackrr7zCkSNHMpyb2ZhZRVEYPXo0GzdupE6dOlhaWlK7dm0CAgKeyb93714aN26MTqfDzc2NBQsWZHscblBQEG+88QYVK1bE0tISV1dX3nvvPR4/fvzM+7O2tubmzZt069YNa2trHBwcmDBhwjN9ERMTw+DBg7Gzs6NUqVIMGjSImJiYF2YB493ZCxcucPz48We+tnr1ahRFoU+fPiQnJzNlyhQaNWqEnZ0dJUuWxMfHhz179rzwGpmNmTUYDHz66adUqFABKysrXn31Vc6ePfvMuffv32fChAnUrVsXa2trbG1t6dixIydPnkw/Zu/evbzyyisADBkyJH0oy5PxwpmNmY2Pj+f999/H1dUVS0tLatasyddff43BYMhwXE4+F7l1+/Zthg0bhqOjIzqdDk9PT5YvX/7Mcb/88guNGjXCxsYGW1tb6taty6xZs9K/npKSwvTp06levTo6nQ57e3tatGhBYGBgnmUVwlTI7Q4hxAvdu3ePjh070rt3b/r374+joyNgLHysra0ZP3481tbW7N69mylTphAbG8tXX331wtddvXo1jx49YuTIkSiKwn//+1969OhBeHj4C+/QHThwgA0bNvD2229jY2PD7Nmz6dmzJ9euXcPe3h6AEydO0KFDB5ydnZk+fTppaWnMmDEDBweHbL3vX3/9lYSEBPz9/bG3t+fw4cPMmTOHGzdu8Ouvv2Y4Ni0tjfbt2+Pl5cXXX3/Nzp07+eabb3Bzc8Pf3x8wFoVdu3blwIEDjBo1ilq1avHbb78xaNCgbOXp168f06dPZ/Xq1TRs2DDDtdeuXYuPjw8VK1bk7t27LF68mD59+jBixAgePXrEkiVLaN++PYcPH37mV/svMmXKFD799FM6depEp06dOH78OO3atSM5OTnDceHh4WzcuJE33niDKlWqcOvWLRYsWECrVq04d+4cLi4u1KpVixkzZjBlyhTeeustfHx8AGjWrFmm1zYYDLz22mvs2bOHYcOGUb9+fbZv386///1vbt68yXfffZfh+Ox8LnLr8ePHtG7dmrCwMEaPHk2VKlX49ddfGTx4MDExMYwdOxaAwMBA+vTpQ5s2bfjyyy8BOH/+PAcPHkw/Ztq0aXzxxRcMHz6cJk2aEBsby9GjRzl+/Dht27Z9qZxCmByDEEL8zzvvvGP45x8LrVq1MgCG+fPnP3N8QkLCM20jR440WFlZGRITE9PbBg0aZKhUqVL68ytXrhgAg729veH+/fvp7Zs2bTIAht9//z29berUqc9kAgwWFhaGsLCw9LaTJ08aAMOcOXPS2/z8/AxWVlaGmzdvprddvnzZYGZm9sxrZiaz9/fFF18YFEUxREREZHh/gGHGjBkZjm3QoIGhUaNG6c83btxoAAz//e9/09tSU1MNPj4+BsDw448/vjDTK6+8YqhQoYIhLS0tvS0gIMAAGBYsWJD+mklJSRnOe/DggcHR0dEwdOjQDO2AYerUqenPf/zxRwNguHLlisFgMBhu375tsLCwMHTu3Nmg1+vTj/vPf/5jAAyDBg1Kb0tMTMyQy2Awfq8tLS0z9M2RI0eyfL///Kw86bNPP/00w3Gvv/66QVGUDJ+B7H4uMvPkM/nVV19leczMmTMNgGHVqlXpbcnJyQZvb2+DtbW1ITY21mAwGAxjx4412NraGlJTU7N8LU9PT0Pnzp2fm0kIkT0yzEAI8UKWlpYMGTLkmfYSJUqk//+jR4+4e/cuPj4+JCQkcOHChRe+bq9evShdunT68yd36cLDw194rq+vL25ubunP69Wrh62tbfq5aWlp7Ny5k27duuHi4pJ+XLVq1ejYseMLXx8yvr/4+Hju3r1Ls2bNMBgMnDhx4pnjR40aleG5j49PhveydetWzMzM0u/UgnGM6rvvvputPGAc53zjxg3279+f3rZ69WosLCx444030l/TwsICAL1ez/3790lNTaVx48aZDlF4np07d5KcnMy7776bYWjGuHHjnjnW0tISjcb410paWhr37t3D2tqamjVr5vi6T2zduhWtVsuYMWMytL///vsYDAa2bduWof1Fn4uXsXXrVpycnOjTp096m7m5OWPGjCEuLo59+/YBUKpUKeLj4587ZKBUqVKcPXuWy5cvv3QuIUydFLNCiBcqX758enH0tLNnz9K9e3fs7OywtbXFwcEhffLYw4cPX/i6FStWzPD8SWH74MGDHJ/75Pwn596+fZvHjx9TrVq1Z47LrC0z165dY/DgwZQpUyZ9HGyrVq2AZ9+fTqd7ZvjC03kAIiIicHZ2xtraOsNxNWvWzFYegN69e6PValm9ejUAiYmJ/Pbbb3Ts2DHDPwyWL19OvXr10sdjOjg4sGXLlmx9X54WEREBQPXq1TO0Ozg4ZLgeGAvn7777jurVq2NpaUnZsmVxcHDg1KlTOb7u09d3cXHBxsYmQ/uTFTae5HviRZ+LlxEREUH16tXTC/assrz99tvUqFGDjh07UqFCBYYOHfrMuN0ZM2YQExNDjRo1qFu3Lv/+978L/ZJqQhRWUswKIV7o6TuUT8TExNCqVStOnjzJjBkz+P333wkMDEwfI5id5ZWymjVv+MfEnrw+NzvS0tJo27YtW7ZsYeLEiWzcuJHAwMD0iUr/fH8FtQJAuXLlaNu2LevXryclJYXff/+dR48e0a9fv/RjVq1axeDBg3Fzc2PJkiUEBAQQGBjIv/71r3xd9urzzz9n/PjxtGzZklWrVrF9+3YCAwOpXbt2gS23ld+fi+woV64coaGhbN68OX28b8eOHTOMjW7ZsiV//fUXS5cupU6dOixevJiGDRuyePHiAsspRHEhE8CEELmyd+9e7t27x4YNG2jZsmV6+5UrV1RM9bdy5cqh0+ky3WTgeRsPPHH69GkuXbrE8uXLGThwYHr7y8w2r1SpErt27SIuLi7D3dmLFy/m6HX69etHQEAA27ZtY/Xq1dja2uLn55f+9XXr1lG1alU2bNiQYWjA1KlTc5UZ4PLly1StWjW9/c6dO8/c7Vy3bh2vvvoqS5YsydAeExND2bJl05/nZEe3SpUqsXPnTh49epTh7uyTYSxP8hWESpUqcerUKfR6fYa7s5llsbCwwM/PDz8/P/R6PW+//TYLFizg448/Tv/NQJkyZRgyZAhDhgwhLi6Oli1bMm3aNIYPH15g70mI4kDuzAohcuXJHbCn73glJyfzww8/qBUpA61Wi6+vLxs3biQyMjK9PSws7JlxllmdDxnfn8FgyLC8Uk516tSJ1NRU5s2bl96WlpbGnDlzcvQ63bp1w8rKih9++IFt27bRo0cPdDrdc7MfOnSIkJCQHGf29fXF3NycOXPmZHi9mTNnPnOsVqt95g7or7/+ys2bNzO0lSxZEiBbS5J16tSJtLQ05s6dm6H9u+++Q1GUbI9/zgudOnUiOjqaNWvWpLelpqYyZ84crK2t04eg3Lt3L8N5Go0mfSOLpKSkTI+xtramWrVq6V8XQmSf3JkVQuRKs2bNKF26NIMGDUrfanXlypUF+uvcF5k2bRo7duygefPm+Pv7pxdFderUeeFWqu7u7ri5uTFhwgRu3ryJra0t69evf6mxl35+fjRv3pxJkyZx9epVPDw82LBhQ47Hk1pbW9OtW7f0cbNPDzEA6NKlCxs2bKB79+507tyZK1euMH/+fDw8PIiLi8vRtZ6sl/vFF1/QpUsXOnXqxIkTJ9i2bVuGu61PrjtjxgyGDBlCs2bNOH36ND/99FOGO7oAbm5ulCpVivnz52NjY0PJkiXx8vKiSpUqz1zfz8+PV199lQ8//JCrV6/i6enJjh072LRpE+PGjcsw2Ssv7Nq1i8TExGfau3XrxltvvcWCBQsYPHgwx44do3Llyqxbt46DBw8yc+bM9DvHw4cP5/79+/zrX/+iQoUKREREMGfOHOrXr58+vtbDw4PWrVvTqFEjypQpw9GjR1m3bh2jR4/O0/cjhCmQYlYIkSv29vb88ccfvP/++3z00UeULl2a/v3706ZNG9q3b692PAAaNWrEtm3bmDBhAh9//DGurq7MmDGD8+fPv3C1BXNzc37//XfGjBnDF198gU6no3v37owePRpPT89c5dFoNGzevJlx48axatUqFEXhtdde45tvvqFBgwY5eq1+/fqxevVqnJ2d+de//pXha4MHDyY6OpoFCxawfft2PDw8WLVqFb/++it79+7Nce5PP/0UnU7H/Pnz2bNnD15eXuzYsYPOnTtnOO4///kP8fHxrF69mjVr1tCwYUO2bNnyzHbE5ubmLF++nMmTJzNq1ChSU1P58ccfMy1mn/TZlClTWLNmDT/++COVK1fmq6++4v3338/xe3mRgICATDdZqFy5MnXq1GHv3r1MmjSJ5cuXExsbS82aNfnxxx8ZPHhw+rH9+/dn4cKF/PDDD8TExODk5ESvXr2YNm1a+vCEMWPGsHnzZnbs2EFSUhKVKlXi008/5d///neevychijvFUJhuowghRAHo1q2bLIskhBDFhIyZFUIUa//cevby5cts3bqV1q1bqxNICCFEnpI7s0KIYs3Z2ZnBgwdTtWpVIiIimDdvHklJSZw4ceKZtVOFEEIUPTJmVghRrHXo0IGff/6Z6OhoLC0t8fb25vPPP5dCVgghigm5MyuEEEIIIYosGTMrhBBCCCGKLClmhRBCCCFEkWVyY2b1ej2RkZHY2NjkaEtFIYQQQghRMAwGA48ePcLFxSXD9tGZMbliNjIyEldXV7VjCCGEEEKIF7h+/ToVKlR47jEmV8w+2W7w+vXr2Nra5vv1UlJS2LFjB+3atcPc3Dzfr1eUSN9kTvola9I3mZN+yZr0TeakX7ImfZO5gu6X2NhYXF1d0+u25zG5YvbJ0AJbW9sCK2atrKywtbWVH4p/kL7JnPRL1qRvMif9kjXpm8xJv2RN+iZzavVLdoaEygQwIYQQQghRZEkxK4QQQgghiiwpZoUQQgghRJFlcmNmhRBCCJF9BoOB1NRU0tLS1I5SIFJSUjAzMyMxMdFk3nN25Ee/mJubo9VqX/p1pJgVQgghRKaSk5OJiooiISFB7SgFxmAw4OTkxPXr12U9+qfkR78oikKFChWwtrZ+qdeRYlYIIYQQz9Dr9Vy5cgWtVouLiwsWFhYmUdzp9Xri4uKwtrZ+4WL9piSv+8VgMHDnzh1u3LhB9erVX+oOrRSzQgghhHhGcnIyer0eV1dXrKys1I5TYPR6PcnJyeh0Oilmn5If/eLg4MDVq1dJSUl5qWJWvktCCCGEyJIUdCK/5NWdfvmECiGEEEKIIkuK2fykT0OJOED5+yEoEQdAL7MihRBCCCHykqrF7P79+/Hz88PFxQVFUdi4ceMLz9m7dy8NGzbE0tKSatWqsWzZsnzPmSvnNsPMOpit6kbjiHmYreoGM+sY24UQQggTkaY3EPLXPTaF3iTkr3uk6Q1qR8qxypUrM3PmzGwfv3fvXhRFISYmJt8yib+pWszGx8fj6enJ999/n63jr1y5QufOnXn11VcJDQ1l3LhxDB8+nO3bt+dz0hw6txnWDoTYyIztsVHGdilohRBCmICAM1G0+HI3fRb9ydhfQumz6E9afLmbgDNR+XI9RVGe+5g2bVquXvfIkSO89dZb2T6+WbNmREVFYWdnl6vrZZcUzUaqrmbQsWNHOnbsmO3j58+fT5UqVfjmm28AqFWrFgcOHOC7776jffv2+RUzZ/RpEDARyOxfngZAgYBJ4N4ZNC+/ULAQQghRGAWcicJ/1fFn/jaMfpiI/6rjzOvfkA51nPP0mlFRfxfJa9asYcqUKVy8eDG97en1TA0GA2lpaZiZvbgUcnBwyFEOCwsLnJyccnSOyL0itTRXSEgIvr6+Gdrat2/PuHHjsjwnKSmJpKSk9OexsbGAcSeLlJSUPM+oRBzA7J93ZDMwQOxNUsP3Y6jUIs+vX5Q86f/8+D4UZdIvWZO+yZz0S9akbzKXnX5JSUnBYDCg1+vR6/UYDAYep2Rv7kea3sDUzWefd1uHaZvP4l21DFrNi2e0lzDXZmvme7ly5dL/38bGBkVR0tv27t1LmzZt+OOPP5gyZQqnT58mICAAV1dX3n//fQ4dOkR8fDy1atXiww8/xM/PD71eD0DVqlUZO3YsY8eOBUCr1bJgwQK2bt3Kjh07KF++PF999RWvvfZahmvdu3ePUqVKsWzZMsaPH8/PP//M+PHjuX79Os2bN2fp0qU4OxsL+tTUVN5//31WrlyJVqtl2LBhREdH8/DhQ3777bdM3++TfE++R//04MEDxo0bxx9//EFSUhItW7Zk1qxZVK9eHYCIiAjeffddDh48SHJyMpUrV+bLL7+kU6dOPHjwgHfffZfAwEDi4uKoUKEC48aNY9SoUZleKzeefK4yW5orJz+zRaqYjY6OxtHRMUObo6MjsbGxPH78mBIlSjxzzhdffMH06dOfad+xY0e+rJtX/n4IjbNxXGjQdm6ejc3z6xdFgYGBakcolKRfsiZ9kznpl6xJ32Tuef1iZmaGk5MTcXFxJCcn8zg5De9v/8yT6xqA6NgkPGfszNbxIeObUsIiZ7/NTExMxGAwpN/EerKL2cSJE/nkk0+oXLkypUqV4saNG7z66qtMmjQJS0tLfvnlF/r06cPhw4dxdXUFjEVXYmJi+msBTJ8+nenTpzNlyhQWLlzIgAEDOHXqFKVLl06/1qNHj9BoNCQmJpKQkMB///tffvjhBzQaDSNHjmTcuHEsWrQIgK+//pqffvqJuXPnUqNGDebPn8/GjRvx8fHJcN2n/fM6/zRgwADCw8P56aefsLGxYfr06XTq1Ik///wTc3NzRo0aRUpKCn/88QclS5bkwoULKIpCbGwskyZN4syZM6xduxZ7e3vCw8N5/Pgxjx49ytH34XmSk5N5/Pgx+/fvJzU1NdP3lh1FqpjNjcmTJzN+/Pj057Gxsbi6utKuXTtsbW3z/HpKhC1EzHvhcfV92uMpd2YJDAykbdu2mJubqx2n0JB+yZr0TeakX7ImfZO57PRLYmIi169fx9raGp1Oh1lyaqbHFQQbWxusLHJWsuh0OhRFSf+7/skNrE8++YSuXbumH1epUiWaN2+e/rx+/fr88ccf7Nmzh9GjRwPGtXZ1Ol2GumHIkCEMHToUgK+++ooFCxZw/vx5OnTokH4tGxsbbG1t0el0pKSksHDhQtzc3AB49913+eSTT9Jfc/HixUyePJm+ffsCsGDBAnbt2oWZmVmW9co/r/O0y5cvs23bNoKCgmjWrBkAP//8M5UqVWL37t288cYbREVF0aNHD7y9vQGoV69e+vnR0dE0atSIVq1aAVC7dm0ePXqUfsc7LyQmJlKiRAlatmyJTqfL8LWsCvjMFKli1snJiVu3bmVou3XrFra2tpnelQWwtLTE0tLymXZzc/P8+YOtakuwdTFO9sr0FyxGZjcPG4+VcbP5970o4qRfsiZ9kznpl6xJ32Tuef2SlpaGoihoNBo0Gg0lLc05NyN781MOX7nP4B+PvPC4ZUNeoUmVMi88LrvDDJ725E7lP//bpEmTDHcx4+LimDZtGlu2bCEqKorU1FQeP37M9evXMxz3pC+e8PT0TH/+pJi8e/duen89ueaTh5WVVfqv9wFcXFy4ffs2Go2Ghw8fcuvWLby8vDKc26hRI/R6fZYbV/zzOk+7ePEiZmZmeHt7p3/NwcGBmjVrcvHiRTQaDWPGjMHf35/AwEB8fX3p2bNnekH79ttv07NnT06cOEG7du147bXXqFOnzjP98DI0Gg2KomT6OczJz2uRWmfW29ubXbt2ZWgLDAxM/xdFoaDRQocv//fknz94Tz3f8zks6wwx1woqmRBCCJFriqJgZWGWrYdPdQec7XTP/C2Y/lqAs50On+oO2Xq9vLoTCFCyZMkMzydMmMBvv/3G559/TlBQEMePH8fDw4Pk5OTnvs4/iy1FUZ47ljSz4w0GdZcpGz58OOHh4QwYMIDTp0/TuHFj5syZAxgn6UdERPDee+8RGRlJ27Zt+fjjj1XNmxVVi9m4uDhCQ0MJDQ0FjEtvhYaGcu2ascCbPHkyAwcOTD9+1KhRhIeH88EHH3DhwgV++OEH1q5dy3vvvadG/Kx5vAZvrgDbf8zStHUxtnebDxbWcC0E5jWHU7+qk1MIIYTIB1qNwlQ/DyDr2zpT/TyyNfkrvx08eJDBgwfTvXt36tati5OTU3odUlDs7OxwdHTkyJG/72anpaVx/PjxXL9mrVq1SE1N5dChQ+lt9+7d4+LFi3h4eKS3ubq6MmrUKDZs2MD777+fPoYXjHdyBw0axKpVq/j2229Zvnx5rvPkJ1WHGRw9epRXX301/fmTsa2DBg1i2bJlREVFZfhAValShS1btvDee+8xa9YsKlSowOLFiwvPslxP83gN3DuTGr6f0KDt1Pdpj9nTwwoqNoUNb8GNw7BhOFzeDp2/AV3+rkknhBBCFIQOdZyZ178h038/R9TDxPR2JzsdU/088nxZrtyqXr06GzZswM/PD0VR+Oijj1S5Y/ruu+/yxRdfUK1aNdzd3ZkzZw4PHjzI1l3p06dPY2Njk/5cURQ8PT3p2rUrI0aMYMGCBdjY2DBp0iTKly+fPmZ43LhxdOzYkRo1avDgwQP27NlDrVq1AJgyZQqNGjWidu3aJCUlsWXLFmrUqJE/b/4lqVrMtm7d+rkfmMx292rdujUnTpzIx1R5SKPFUKkFN8/GGid7PT0+tkwVGLINgr6Gff+F07/CtUPQYyFUKkTDJoQQQohc6lDHmbYeThy+cp/bjxIpZ6OjSZXsLcdVUL799luGDh1Ks2bNKFu2LB988AEPHjwo8BwTJ04kOjqagQMHotVqeeutt2jfvv0zS1ZlpmXLlhmea7VaUlNT+fHHHxk7dixdunQhOTmZli1bsnXr1vQhD2lpabzzzjvcuHEDW1tbOnTowHfffQcY18qdPHkyV69epUSJErRo0YIlS5bk/RvPA4pB7QEbBSw2NhY7OzsePnyYL6sZ/FNKSgpbt26lU6dOWQ9mvn4Y1g+HmAhQNODzPrSaCNriPVkhW31jgqRfsiZ9kznpl6xJ32QuO/2SmJjIlStXqFKlyjMzzYszvV5PbGwstra2eTbRKbc5atWqxZtvvsknn3yiWo6n8+R1vzzvM5aTeq1ITQArtlybwKgD4NkXDHrY/xUsbQ/3/lI7mRBCCCEKQEREBIsWLeLSpUucPn0af39/rly5kr5Ul8iaFLOFhc4Wus+D1380jpu9eQzm+8DxFWBaN8+FEEIIk6PRaFi2bBmvvPIKzZs35/Tp0+zcuTN9DKvIWpFaZ9Yk1OlhvFO7YSREHIDN78LlHeA3G6xevBafEEIIIYoeV1dXDh48qHaMIknuzBZGdhVg0GbwnQYaMzj/O8xrBuF71U4mhBBCCFGoSDFbWGm00OI9GL4T7KvDoyhY0RW2fwipSWqnE0IIIYQoFKSYLexcGsDIfdDYuP8zIXNhURu4fUHdXEIIIYQQhYAUs0WBRUno8h30/hms7OHWaVjYCg4vkslhQgghhDBpUswWJe6dwD8Y3NpAaiJsnQCre0HcbbWTCSGEEEKoQorZosbGCfqtgw5fgtbSuA3uvGZwaYfayYQQQgghCpwUs0WRRgNNR8Fbe6BcbYi/A6vfgC0TIOWx2umEEEKIv+nT4EoQnF5n/K8+Te1EL9SlSxfee++99OeVK1dm5syZzz1HURQ2btz40tfOq9cxJVLMFmWOtWHEbmj6tvH5kUWwoBVEnVI3lxBCCAFwbjPMrAPLu8D6Ycb/zqxjbM8Hfn5+dOjQIdOvBQUFoSgKp07l/O/II0eO8NZbb71svAymTZtG/fr1n2mPioqiY8eOeXqtf1q2bBmlSpXK12sUJClmizpzHXT4AvqvB2tHuHsRFreB4Dmg16udTgghhKk6txnWDoTYyIztsVHG9nwoaIcNG0ZgYCA3btx45ms//vgjjRs3pl69ejl+XQcHB6ysrPIi4gs5OTlhaWlZINcqLqSYLS6q+Ronh9XsDGnJsOMjWNnt2T9EhBBCiNwwGCA5PnuPxFjY9gGQ2Yo7/2sLmGg8Ljuvl82Ve7p06YKDgwPLli3L0B4XF8evv/7KsGHDuHfvHn369KF8+fJYWVlRt25dfv755+e+7j+HGVy+fJmWLVui0+nw8PAgMDDwmXMmTpxIjRo1sLKyomrVqnz88cekpKQAxjuj06dP5+TJkyiKgqIo6Zn/Oczg9OnT/Otf/6JEiRLY29vz1ltvERcXl/71wYMH061bN77++mucnZ2xt7fnnXfeSb9Wbly7do2uXbtibW2Nra0tb775Jrdu3Ur/+smTJ3n11VexsbHB1taWRo0acfToUQAiIiLw8/OjdOnSlCxZktq1a7N169ZcZ8kO2c62OClZFnr/BMeWQcBkuLLPODnMbzZ4vKZ2OiGEEEVZSgJ87pJHL2Yw3mz5P9fsHf6fSOMylS9gZmbGwIEDWbZsGR9++CGKogDw66+/kpaWRp8+fYiLi6NRo0ZMnDgRW1tbtmzZwoABA3Bzc6NJkyYvvIZer6dHjx44Ojpy6NAhHj58yLhx4545zsbGhmXLluHi4sLp06cZMWIENjY2fPDBB/Tq1YszZ84QEBDAzp07AbCzs3vmNeLj42nfvj3e3t4cOXKE27dvM3z4cEaPHp2hYN+zZw/Ozs7s2bOHsLAwevXqRf369RkxYsQL309m7+9JIbtv3z5SU1N555136NOnT3qR3a9fPxo0aMC8efPQarWEhoZibm4OwDvvvENycjL79++nZMmSnDt3Dmtr6xznyAkpZosbRYHGQ6BSc9gwHKJOwtoB0GAAdPg/sMzfD5QQQgihpqFDh/LVV1+xb98+WrduDRiHGPTs2RM7Ozvs7OyYMGFC+vHvvvsu27dvZ+3atdkqZnfu3MmFCxfYvn07Li7G4v7zzz9/ZpzrRx99lP7/lStXZsKECfzyyy988MEHlChRAmtra8zMzHBycsryWqtXryYxMZEVK1ZQsqSxmJ87dy5+fn58+eWXODo6AlC6dGnmzp2LVqvF3d2dzp07s2vXrlwVs7t27eL06dNcuXIFV1fjPzZWrFhB7dq1OX78OK1bt+batWv8+9//xt3dHYDq1aunn3/t2jV69uxJ3bp1AahatWqOM+SUFLPFlUMNGLYT9n4OB2bCiZUQcRB6LIYKjdROJ4QQoqgxtzLeIc2OiGD46fUXH9dvHVRqlr1rZ5O7uzvNmjVj6dKltG7dmrCwMIKCgpgxYwYAaWlpfP7556xdu5abN2+SnJxMUlJStsfEnj9/HldX1/RCFsDb2/uZ49asWcPs2bP566+/iIuLIzU1FVtb22y/jyfX8vT0TC9kAZo3b45er+fixYvpxWzt2rXRarXpxzg7O3P69OkcXevpa7q6uqYXsgAeHh6UKlWKS5cu0bp1a8aPH8/w4cNZuXIlvr6+vPHGG7i5uQEwZswY/P392bFjB76+vvTs2TNX45RzQsbMFmdmFuA7DQb9DrYV4H44LGkL+78qEkujCCGEKEQUxfir/uw83P4Fti6AktWLgW1543HZeT0lq9fJ3LBhw1i/fj2PHj3ixx9/xM3NjVatWgHw1VdfMWvWLCZOnMiePXsIDQ2lffv2JCcnv1z/PCUkJIR+/frRqVMn/vjjD06cOMGHH36Yp9d42pNf8T+hKAr6fJwEPm3aNM6ePUvnzp3ZvXs3Hh4e/PbbbwAMHz6c8PBwBgwYwOnTp2ncuDFz5szJtywgxaxpqOID/gegdncwpMHuT2FZZ4i5pnYyIYQQxZFGa9zcB3i2oP3f8w7/ZzwuH7z55ptoNBpWr17NihUrGDp0aPr42YMHD9K1a1f69++Pp6cnVatW5dKlS9l+7Vq1anH9+nWioqLS2/78888MxwQHB1OpUiU+/PBDGjduTPXq1YmIiMhwjIWFBWlpz7+xVKtWLU6ePEl8fHx628GDB9FoNNSsWTPbmXPiyfu7fv16etu5c+eIiYnJcM0aNWrw3nvvsWPHDnr06MGPP/6Y/jVXV1dGjRrFhg0beP/991m0aFG+ZH1CillTUaI0vP4jdJsPFtZwLQTmNYdTv6qdTAghRHHk8Rq8uQJsnTO227oY2/NxYrK1tTW9evVi8uTJREVFMXjw4PSvVa9encDAQIKDgzl//jwjR47MMFP/RXx9falRowaDBg3i5MmTBAUF8eGHH2Y4pnr16ly7do1ffvmFv/76i9mzZ6ffuXyicuXKXLlyhdDQUO7evUtSUtIz1+rXrx86nY5BgwZx5swZ9uzZw7vvvsuAAQPShxjkVlpaGqGhoRke58+fx9fXl7p169KvXz+OHz/O4cOHGThwIK1ataJBgwY8fvyY0aNHs3fvXiIiIjh48CBHjhyhVq1aAIwbN47t27dz5coVjh8/zp49e9K/ll+kmDUligL1+8CoA1ChCSTFGieJrR8OiQ/VTieEEKK48XgNxp2BQX9AzyXG/447XSAr7AwbNowHDx7Qvn37DONbP/roIxo2bEj79u1p3bo1Tk5OdOvWLduvq9Fo+O2333j8+DFNmjRh+PDhfPbZZxmOee2113jvvfcYPXo09evXJzg4mI8//jjDMT179qRDhw68+uqrODg4ZLo8mJWVFdu3b+f+/fu88sorvP7667Rp04a5c+fmrDMyERcXR4MGDTI8/Pz8UBSFTZs2Ubp0aVq2bImvry9Vq1ZNz6fVarl37x4DBw6kRo0avPnmm3Ts2JHp06cDxiL5nXfeoVatWnTo0IEaNWrwww8/vHTe51EMhmwu3lZMxMbGYmdnx8OHD3M8EDs3UlJS2Lp1K506dXpmTIuq0lIh6GvY91/j0AO7itBjQfYG4ueRQts3KpN+yZr0TeakX7ImfZO57PRLYmIiV65coUqVKuh0ugJOqB69Xk9sbCy2trZoNHLP74n86JfnfcZyUq/Jd8lUac2g9SQYGgClKsHDa8ZxtLs/hbTcL7QshBBCCFGQpJg1da5NjMMOPPuCQW9c6WBpe7j3l9rJhBBCCCFeSIpZATpb6D7POEFMZwc3j8F8Hzi+IttbCAohhBBCqEGKWfG3Oj3APxgqtYCUeNj8rnH3sIT7aicTQgghhMiUFLMiI7sKMGizcbMFjRmc/x3mNYPwvWonE0IIoQITmycuClBefbakmBXP0mihxXswfCfYV4dHUbCiK2z/EFKfXQdPCCFE8fNklYOEhASVk4ji6smOaE9vxZsbZnkRRhRTLg1g5D7Y8REcXQohcyF8H/RcDOXc1U4nhBAiH2m1WkqVKsXt27cB45qnSg63lS2K9Ho9ycnJJCYmytJcT8nrftHr9dy5cwcrKyvMzF6uHJViVjyfRUno8h1UawubR8Ot07CwFbT7FF4ZnuP9soUQQhQdTk5OAOkFrSkwGAw8fvyYEiVKmETxnl350S8ajYaKFSu+9OtJMSuyx70TlA+GjW/DX7tg6wS4HAhd54J1ObXTCSGEyAeKouDs7Ey5cuVISTGNNchTUlLYv38/LVu2lI02npIf/WJhYZEnd3mlmBXZZ+ME/dbB4YUQOAUubzdODuv6A9Rop3Y6IYQQ+USr1b70uMaiQqvVkpqaik6nk2L2KYW5X2QwiMgZjQaajoK39kC52hB/B1a/AVsmQMpjtdMJIYQQwsRIMStyx7E2jNgNTd82Pj+yCBa0gqhT6uYSQgghhEmRYlbknrkOOnwB/deDtSPcvQiL20DwHNDr1U4nhBBCCBMgxax4edV8jTuH1ewMacnGpbxWdoPYSLWTCSGEEKKYk2JW5I2SZaH3T9BlJphbwZV9xslh5zarnUwIIYQQxZgUsyLvKAo0HgIj94NzfXj8ANYOgE2jISlO7XRCCCGEKIakmM1HaXoDh67c59hdhUNX7pOmN5H9rctWh2GBxi1xUeDESljgAzeOqZ1MCCGEEMWM6sXs999/T+XKldHpdHh5eXH48OEsj01JSWHGjBm4ubmh0+nw9PQkICCgANNmX8CZKFp8uZv+S4+y4rKW/kuP0uLL3QSciVI7WsEwswDfaTDod7CtAPfDYUlb2P8V6NPUTieEEEKIYkLVYnbNmjWMHz+eqVOncvz4cTw9PWnfvn2W2+Z99NFHLFiwgDlz5nDu3DlGjRpF9+7dOXHiRAEnf76AM1H4rzpO1MPEDO3RDxPxX3XcdApagCo+4H8AancHQxrs/hSWdYaYa2onE0IIIUQxoGox++233zJixAiGDBmCh4cH8+fPx8rKiqVLl2Z6/MqVK/nPf/5Dp06dqFq1Kv7+/nTq1IlvvvmmgJNnLU1vYPrv58hsQMGTtum/nzOdIQcAJUrD6z9Ct/lgYQ3XQmBec5Qz69ROJoQQQogiTrXtbJOTkzl27BiTJ09Ob9NoNPj6+hISEpLpOUlJSeh0ugxtJUqU4MCBA1leJykpiaSkpPTnsbGxgHHIQn7sM33oyv1n7sg+zQBEPUwkJOw2XlXK5Pn1C7Xar4NLY7Sb/NHcPILZplE0LO1NSpwXWNurna7QePK5NJV90HNC+iZz0i9Zk77JnPRL1qRvMlfQ/ZKT6ygGg0GVW4SRkZGUL1+e4OBgvL2909s/+OAD9u3bx6FDh545p2/fvpw8eZKNGzfi5ubGrl276Nq1K2lpaRkK1qdNmzaN6dOnP9O+evVqrKys8u4N/c+xuworLr94/+qB1dNoVNaE7s4+RTGkUSN6MzWiN6FBT4JFWY5VGsl965pqRxNCCCFEIZCQkEDfvn15+PAhtra2zz1WtTuzuTFr1ixGjBiBu7s7iqLg5ubGkCFDshyWADB58mTGjx+f/jw2NhZXV1fatWv3ws7JDfsr91lx+egLj2vn42V6d2Yz8CP56lDSfh1KyeQ7tAj7An2z99D7TACtudrhVJWSkkJgYCBt27bF3Ny0++KfpG8yJ/2SNembzEm/ZE36JnMF3S9PfpOeHaoVs2XLlkWr1XLr1q0M7bdu3cLJySnTcxwcHNi4cSOJiYncu3cPFxcXJk2aRNWqVbO8jqWlJZaWls+0m5ub58s3w7taOZztdEQ/TMx03OwTx68/xLtaObQaJc8zFBmVvdnl/ikd2YPm1C9oD36D9upe6LEI7N3UTqe6/PqMFgfSN5mTfsma9E3mpF+yJn2TuYLql5xcQ7UJYBYWFjRq1Ihdu3alt+n1enbt2pVh2EFmdDod5cuXJzU1lfXr19O1a9f8jpttWo3CVD8PAP5Zpj79/NvAy/ReGMKNBwkFlq0wStWWIM1vrnGCmM4Obh6D+T5wfAWoMwJGCCGEEEWIqqsZjB8/nkWLFrF8+XLOnz+Pv78/8fHxDBkyBICBAwdmmCB26NAhNmzYQHh4OEFBQXTo0AG9Xs8HH3yg1lvIVIc6zszr3xAnu4yT1ZzsdMzr15Bv3vCkpIWWI1cf0HFmEJtCb6qUtBCp0wP8g6GyD6TEw+Z3jbuHJdxXO5kQQgghCjFVx8z26tWLO3fuMGXKFKKjo6lfvz4BAQE4OjoCcO3aNTSav+vtxMREPvroI8LDw7G2tqZTp06sXLmSUqVKqfQOstahjjNtPZwICbvNjqBDtPPxyjCs4JXKZRi35gTHr8Uw9pdQdl+4zSfd6mCrM+FfadhVgIGbIHgO7P4Ezv8ON45C9/lQtbXa6YQQQghRCKk+AWz06NGMHj0606/t3bs3w/NWrVpx7ty5AkiVN7QaBa8qZbh33oBXlTIZxsdWtLdi7Uhv5u4JY87uMDaFRnL06gNm9q7PK5VNeGKYRgstxkHVVrB+BNy7DCu6gvdoaDMFzJ4d/yyEEEII06X6dramzEyrYZxvDdaO9Ma1TAluxjym14IQvtlxkZQ0vdrx1OXSAEbug8ZDjc9D5sKiNnD7grq5hBBCCFGoSDFbCDSqVJqtY3zo2bACegPM2R3G6/NDuHI3Xu1o6rIoCV2+g94/g5U93DoNC1vB4UUyOUwIIYQQgBSzhYaNzpxv3vRkbt8G2OrMOHk9hs6zg1hz5Boq7WtReLh3Mk4Oc2sDqYmwdQKs7gVxt9VOJoQQQgiVSTFbyHSp50LAuJZ4VSlDQnIaE9efxn/VcR7EJ6sdTV02TtBvHXT4ErSWcHk7zGsGl3aonUwIIYQQKpJithByKVWC1SOaMrGDO2YahYCz0XSYtZ+DYXfVjqYujQaajoK39kC52hB/B1a/AVsmQMpjtdMJIYQQQgVSzBZSWo2Cf2s3fnu7OVUdSnIrNol+iw/x2ZZzJKWmqR1PXY61YcRuaPq28fmRRbCgFUSdUjeXEEIIIQqcFLOFXN0Kdvzxbgv6eVUEYFHQFbp9H8zlW49UTqYycx10+AL6rwdrR7h7ERa3Ma5RqzfxlSCEEEIIEyLFbBFgZWHGZ93rsmhgY8qUtOB8VCxd5hxgZchVmRxWzdc4OaxmZ0hLhh0fwcpuEBupdjIhhBBCFAApZouQth6OBIz1oWUNB5JS9Xy86SzDlh/lzqMktaOpq2RZ6P0TdJkJ5lZwZZ9xcti5TWonE0IIIUQ+k2K2iClnq2PZ4FeY6ueBhZmG3Rdu03HWfvZcMPFlqhQFGg+BkfvBuT48fgBrB8Km0ZAUp3Y6IYQQQuQTKWaLII1GYUjzKmwe3Rx3JxvuxiUzZNkRpmw6Q2KKiU8OK1sdhgVCi/cABU6shAU+cOOY2smEEEIIkQ+kmC3C3J1s2fhOc4Y2rwLAipAIusw5wNnIhyonU5mZBfhOg0G/g20FuB8OS9rC/q9Ab+LFvhBCCFHMSDFbxOnMtUzx82D50CY42FgSdjuO7t8Hs2h/OHq9iU8Oq+ID/gegdg8wpMHuT2FZZ4i5pnYyIYQQQuQRKWaLiVY1HAgY60NbD0eS0/R8tvU8A5YeIvphotrR1FWiNLy+FLovAAsbuBYC85rDqV/VTiaEEEKIPCDFbDFib23JwgGN+Lx7XXTmGg6G3aPDrP0EnIlSO5q6FAU8e8OoIKjQBJJiYcNwWD8cEk18SIYQQghRxEkxW8woikJfr4r88a4PdcrbEpOQwqhVx5m47hTxSalqx1NXmSowZBu0ngyKFk7/CvNaQESw2smEEEIIkUtSzBZT1cpZs8G/Of6t3VAUWHP0Op1nBxF6PUbtaOrSmkHrSTA0AEpVgofXjONod38KaSlqpxNCCCFEDkkxW4xZmGmY2MGd1cOb4mKn4+q9BHrOC2bu7sukmfrkMNcmMOoAePYFg9640sHS9nDvL7WTCSGEECIHpJg1Ad5u9mwb25LO9ZxJ0xv4esclei8M4caDBLWjqUtnC93nwes/gs4Obh6D+T5wfAWY+jbBQgghRBEhxayJsLMyZ26fBnzzhiclLbQcufqAjjOD2BR6U+1o6qvTA/yDobIPpMTD5ndh7QBIuK92MiGEEEK8gBSzJkRRFHo2qsC2sS1pWLEUj5JSGftLKGN/OUFsoomPF7WrAAM3ge900JjB+d9hXjMI36t2MiGEEEI8hxSzJqiivRVrR3ozzrc6Wo3CptBIOs4M4vAVE78TqdFCi3EwfCfYV4dHUbCiK2z/EFKT1E4nhBBCiExIMWuizLQaxvnWYO1Ib1zLlOBmzGN6Lwzhmx0XSUnTqx1PXS4NYOQ+aDzU+DxkLixqA7cvqJtLCCGEEM+QYtbENapUmq1jfOjZsAJ6A8zZHcbr80O4cjde7WjqsigJXb6D3j+DlT3cOg0LW8HhRTI5TAghhChEpJgV2OjM+eZNT+b2bYCtzoyT12PoPDuINUeuYTD1ws29E/iHgFsbSE2ErRNgdS+Iu612MiGEEEIgxax4Spd6LgSMa4lXlTIkJKcxcf1p/Fcd50F8strR1GXjCP3WQYcvQWsJl7cbJ4dd2qF2MiGEEMLkSTErMnApVYLVI5oysYM7ZhqFgLPRdJi1n4Nhd9WOpi6NBpqOgrf2QLnaEH8HVr8BWyZAymO10wkhhBAmS4pZ8QytRsG/tRu/vd2cqg4luRWbRL/Fh/hsyzmSUtPUjqcux9owYjc0fdv4/MgiWNAKok6pm0sIIYQwUVLMiizVrWDHH++2oJ9XRQAWBV2h2/fBXL71SOVkKjPXQYcvoP96sHaEuxdhcRsIngN6E18JQgghhChgUsyK57KyMOOz7nVZNLAxZUpacD4qli5zDrAy5KpMDqvma9w5rGZnSEuGHR/Bym4QG6l2MiGEEMJkSDErsqWthyMBY31oWcOBpFQ9H286y7DlR7nzyMQ3EyhZFnr/BF1mgrkVXNlnnBx2bpPayYQQQgiTIMWsyLZytjqWDX6FqX4eWJhp2H3hNh1n7WfPBRNfpkpRoPEQGLkfnOvD4wewdiBsGg1JcWqnE0IIIYo1KWZFjmg0CkOaV2Hz6Oa4O9lwNy6ZIcuOMGXTGRJTTHxyWNnqMCwQWrwHKHBiJSzwgRvH1E4mhBBCFFtSzIpccXeyZeM7zRnavAoAK0Ii6DLnAGcjH6qcTGVmFuA7DQb9DrYV4H44LGkL+78CvYkX+0IIIUQ+kGJW5JrOXMsUPw+WD22Cg40lYbfj6P59MIv2h6PXm/jksCo+4H8AavcAQxrs/hSWdYYHEWonE0IIIYoVKWbFS2tVw4GAsT609XAkOU3PZ1vPM2DpIaIfJqodTV0lSsPrS6H7ArCwgWshML8FnPpV7WRCCCFEsSHFrMgT9taWLBzQiM+716WEuZaDYffoMGs/AWei1I6mLkUBz94wKggqNIGkWNgwHNYPh0QTH5IhhBBC5AEpZkWeURSFvl4V+WNMC+qWtyMmIYVRq44zcd0p4pNS1Y6nrjJVYMg2aD0ZFC2c/hXmtYCIYLWTCSGEEEWaFLMiz7k5WLPevxn+rd1QFFhz9DqdZwcRej1G7Wjq0ppB60kwNABKVYKH14zjaHd/CmkpxmP0aSgRByh/PwQl4oBMGhNCCCFeQPVi9vvvv6dy5crodDq8vLw4fPjwc4+fOXMmNWvWpESJEri6uvLee++RmGjiYzMLIQszDRM7uLN6eFNc7HRcvZdAz3nBzN19mTRTnxzm2gRGHQDPvmDQG1c6WNoeDi2EmXUwW9WNxhHzMFvVDWbWgXOb1U4shBBCFFqqFrNr1qxh/PjxTJ06lePHj+Pp6Un79u25fTvzRfhXr17NpEmTmDp1KufPn2fJkiWsWbOG//znPwWcXGSXt5s928a2pHM9Z9L0Br7ecYneC0O48SBB7Wjq0tlC93nw+o+gs4Obx2Dbv5/dCjc2yrgBgxS0QgghRKZULWa//fZbRowYwZAhQ/Dw8GD+/PlYWVmxdOnSTI8PDg6mefPm9O3bl8qVK9OuXTv69Onzwru5Ql12VubM7dOAb97wpKSFliNXH9BxZhCbT5r45DCAOj1gZBBoLbI44H93sQMmyZADIYQQIhNmal04OTmZY8eOMXny5PQ2jUaDr68vISEhmZ7TrFkzVq1axeHDh2nSpAnh4eFs3bqVAQMGZHmdpKQkkpKS0p/HxsYCkJKSQkpKSh69m6w9uUZBXKuwe62eI/Ur2DBh3WlOXH/I++tO06ishqaPHlPGRu106lHuhWOWlvycIwwQe5PU8P0YKrUosFyFkfw8ZU76JWvSN5mTfsma9E3mCrpfcnIdxWAwqDKAMTIykvLlyxMcHIy3t3d6+wcffMC+ffs4dOhQpufNnj2bCRMmYDAYSE1NZdSoUcybNy/L60ybNo3p06c/07569WqsrKxe/o2IHEszwI4bCjtuaNCjUMbSQP9qabjZqp1MHeXvh9A4IuvP8BNHK/lzs4z3C48TQgghirqEhAT69u3Lw4cPsbV9foGg2p3Z3Ni7dy+ff/45P/zwA15eXoSFhTF27Fg++eQTPv7440zPmTx5MuPHj09/Hhsbi6urK+3atXth5+SFlJQUAgMDadu2Lebm5vl+vaLCDzgSfpd3Vx/jXpLC3HNmjGpZldGvVsVcq/q8xAKlRNhCNorZ+j7t8ZQ7s/LzlAnpl6xJ32RO+iVr0jeZK+h+efKb9OxQrZgtW7YsWq2WW7duZWi/desWTk5OmZ7z8ccfM2DAAIYPHw5A3bp1iY+P56233uLDDz9Eo3m2CLK0tMTS0vKZdnNz8wL9kBb09YqCV6qW5YN6afyZWpHfTkTyw75wDobfZ2av+lQpW1LteAWnakuwdTFO9iLrX5SY3bsEbq2NGzGYOPl5ypz0S9akbzIn/ZI16ZvMFVS/5OQaqt0Cs7CwoFGjRuzatSu9Ta/Xs2vXrgzDDp6WkJDwTMGq1WoBUGm0hHhJOjP4b486zO3bAFudGSevx9B5dhBrjlwzne+pRgsdvvzfk38Wqk893/YBrO4FcZmv9iGEEEKYIlV/nzt+/HgWLVrE8uXLOX/+PP7+/sTHxzNkyBAABg4cmGGCmJ+fH/PmzeOXX37hypUrBAYG8vHHH+Pn55de1IqiqUs9FwLGtaRp1TIkJKcxcf1p/Fcd50H88yZGFSMer8GbK8DWOWO7rQu8scJY7Got4fJ2mNcMLu1QJ6cQQghRyKg6ZrZXr17cuXOHKVOmEB0dTf369QkICMDR0RGAa9euZbgT+9FHH6EoCh999BE3b97EwcEBPz8/PvvsM7XegshDLqVK8NPwpiwKCufr7RcJOBvNiesP+PbN+jSvVlbtePnP4zVw70xq+H5Cg7ZT36c9ZlVbGu/cAlTxgfUj4PZZWP0GvDIC2n0C5iXUzS2EEEKoSPUJYKNHj2b06NGZfm3v3r0ZnpuZmTF16lSmTp1aAMmEGrQahVGt3GjuVpaxa04QfieefosPMcKnChPa18TSrJjfgddoMVRqwc2zscbJXpqn3q9jbRixG3ZNhz9/gCOL4Mp+6LkYnOupl1kIIYRQkWlNGxdFRt0Kdvzxbgv6eVUEYFHQFbp9H8zlW49UTqYycx10+AL6rwdrR7h7ERa3geA5oNernU4IIYQocFLMikLLysKMz7rXZdHAxpQpacH5qFi6zDnAypCrpjM5LCvVfME/GGp2hrRk2PERrOz27Ha4QgghRDEnxawo9Np6OBIw1oeWNRxIStXz8aazDFt+lDuPkl58cnFWsiz0/gm6zARzK7iyzzg57NxmtZMJIYQQBUaKWVEklLPVsWzwK0z188DCTMPuC7fpOGs/ey6Y+DJVigKNh8DI/eBcHx4/gLUDYNNoSIpTO50QQgiR76SYFUWGRqMwpHkVNo9ujruTDXfjkhmy7AhTNp0hMSVN7XjqKlsdhgVCi/cABU6shAU+cOOY2smEEEKIfCXFrChy3J1s2fhOc4Y2rwLAipAIusw5wNnIhyonU5mZBfhOg0G/g20FuB8OS9rC/q9Ab+LFvhBCiGJLillRJOnMtUzx82D50CY42FgSdjuO7t8Hs2h/OHq9iU8Oq+ID/gegdg8wpMHuT2FZZ4i5pnYyIYQQIs9JMSuKtFY1HAgY60NbD0eS0/R8tvU8A5YeIvphotrR1FWiNLy+FLovAAsbuBYC85rDqV/VTiaEEELkKSlmRZFnb23JwgGN+Lx7XUqYazkYdo8Os/az7XSU2tHUpSjg2RtGBUGFJpAUCxuGw/rhkGjiQzKEEEIUG1LMimJBURT6elXkjzEtqFvejpiEFPx/Os7EdaeIT0pVO566ylSBIdug9WRQtHD6V5jXAiJC1E4mhBBCvDQpZkWx4uZgzXr/Zvi3dkNRYM3R63SeHUTo9Ri1o6lLawatJ8HQAChdGR5eg2WdjONp01LUTieEEELkmhSzotixMNMwsYM7q4c3xcVOx9V7CfScF8zc3ZdJM/XJYa5NYNQB8OwLBr1xpYOl7eHeX2onE0IIIXJFillRbHm72bNtbEu61HMmTW/g6x2X6L0whBsPEtSOpi5LG+g+D17/EXR2cPMYzPeB4yvB1LcJFkIIUeRIMSuKNTsrc+b0acC3b3pibWnGkasP6DgziE2hN9WOpr46PcA/GCr7QEo8bB4NawdCwn21kwkhhBDZJsWsKPYURaFHwwpsHeNDw4qleJSUythfQhn7ywliE018vKhdBRi4CXyng8YMzm+Gec0gfK/ayYQQQohskWJWmIyK9lasHenNON/qaDUKm0Ij6TgziMNXTPxOpEYLLcbB8J1gXx0eRcGKrrD9Q0hNUjudEEII8VxSzAqTYqbVMM63BmtHeuNapgQ3Yx7Te2EI3+y4SEqaXu146nJpACP3QeOhxuchc2FRG7h9Qd1cQgghxHNIMStMUqNKpdk6xoeeDSugN8Cc3WG8Pj+EK3fj1Y6mLouS0OU76P0zWNnDrdOwsBUcXiSTw4QQQhRKUswKk2WjM+ebNz2Z27cBtjozTl6PofPsINYcuYbB1As3907gHwJubSA1EbZOgNW9IO622smEEEKIDKSYFSavSz0XAsa1pGnVMiQkpzFx/Wn8Vx3nQXyy2tHUZeMI/dZBhy9BawmXtxsnh13aoXYyIYQQIp0Us0IALqVK8NPwpkzq6I6ZRiHgbDQdZu3nYNhdtaOpS6OBpqPgrT1QrjbE34HVb8CWCZDyWO10QgghhBSzQjyh1SiMauXGb283p6pDSW7FJtFv8SE+23KOpNQ0teOpy7E2jNgNTd82Pj+yCBa2hqhTqsYSQgghpJgV4h/qVrDjj3db0M+rIgCLgq7Q7ftgLt96pHIylZnroMMX0H89WDvCnQuwuA0EzwG9ia8EIYQQQjVSzAqRCSsLMz7rXpdFAxtTpqQF56Ni6TLnACtDrsrksGq+xp3DanaGtGTY8RGs7AaxkWonE0IIYYKkmBXiOdp6OBIwzoeWNRxIStXz8aazDFt+lDuPTHwzgZJlofdP0GUmmFvBlX3GyWHnNqudTAghhImRYlaIFyhno2PZ4FeY6ueBhZmG3Rdu03HWfvZcMPFlqhQFGg+BkfvBuT48fgBrB8Cm0ZAUp3Y6IYQQJkKKWSGyQaNRGNK8CptHN8fdyYa7cckMWXaEKZvOkJhi4pPDylaHYYHQ4j1AgRMrYYEP3DymdjIhhBAmQIpZIXLA3cmWje80Z2jzKgCsCImgy5wDnI18qHIylZlZgO80GPQ72FaA++GwpB3s/wr0Jl7sCyGEyFdSzAqRQzpzLVP8PFg+tAkONpaE3Y6j+/fBLNofjl5v4pPDqviA/wGo3QP0qbD7U1jWBWKuqZ1MCCFEMSXFrBC51KqGAwFjfWjr4Uhymp7Ptp5nwNJDRD9MVDuaukqUhteXQvcFYGED14JhXnM49avayYQQQhRDUswK8RLsrS1ZOKARn3evSwlzLQfD7tFh1n62nY5SO5q6FAU8e8OoIKjQBJJiYcNwWD8CEk18SIYQQog8JcWsEC9JURT6elXkjzEtqFvejpiEFPx/Os7EdaeIT0pVO566ylSBIdug9WRQtHB6LcxrAREhaicTQghRTEgxK0QecXOwZr1/M/xbu6EosObodTrPDiL0eoza0dSlNYPWk2BoAJSuDA+vwbJOxvG0aSlqpxNCCFHESTErRB6yMNMwsYM7q4c3xcVOx9V7CfScF8zc3ZdJM/XJYa5NYNQB8OwLBr1xpYOl7eHeX2onE0IIUYRJMStEPvB2s2fb2JZ0qedMmt7A1zsu0XthCNfvJ6gdTV2WNtB9Hrz+I+jsjGvRzveB4yvB1LcJFkIIkStSzAqRT+yszJnTpwHfvumJtaUZR64+oNOsIDaF3lQ7mvrq9AD/YKjsAynxsHk0rB0ICffVTiaEEKKIkWJWiHykKAo9GlZg6xgfGlYsxaOkVMb+EsrYX04Qm2ji40XtKsDATeA7HTTmcH4zzGsG4XvVTiaEEKIIkWJWiAJQ0d6KtSO9GedbHa1GYVNoJB1nBnH4ionfidRoocU4GB4I9tXhURSs6Ao7PoLUJLXTCSGEKAKkmBWigJhpNYzzrcHakd64linBzZjH9F4Ywjc7LpKSpgcgTW/g0JX7HLurcOjKfdOZNObSAEbug8ZDjc+D58DiNnDnorq5hBBCFHqFopj9/vvvqVy5MjqdDi8vLw4fPpzlsa1bt0ZRlGcenTt3LsDEQuReo0ql2TrGh54NK6A3wJzdYbw+P4TlwVdp8eVu+i89yorLWvovPUqLL3cTcMZENmCwKAldvoPeP4OVPUSfhgUt4fAimRwmhBAiS6oXs2vWrGH8+PFMnTqV48eP4+npSfv27bl9+3amx2/YsIGoqKj0x5kzZ9BqtbzxxhsFnFyI3LPRmfPNm57M7dsAW50ZJ6/HMHXzWaL+sRVu9MNE/FcdN52CFsC9E/iHgFsbSE2ErRNgdS+Iu6N2MiGEEIWQ6sXst99+y4gRIxgyZAgeHh7Mnz8fKysrli5dmunxZcqUwcnJKf0RGBiIlZWVFLOiSOpSz4UtY3yw0CqZfv3J/cjpv58znSEHADaO0G8ddPgStJZweTvM80YJC1Q7mRBCiELGTM2LJycnc+zYMSZPnpzeptFo8PX1JSQke9tdLlmyhN69e1OyZMlMv56UlERS0t8TSWJjYwFISUkhJSX/Z5M/uUZBXKuokb4xirj7iOS0rAtVAxD1MJGQsNt4VSlTcMEKg0bDwNUbs02jUG6fw2xNH+qW9SUloQVY2aqdrtCQn6WsSd9kTvola9I3mSvofsnJdRSDQb3BaJGRkZQvX57g4GC8vb3T2z/44AP27dvHoUOHnnv+4cOH8fLy4tChQzRp0iTTY6ZNm8b06dOfaV+9ejVWVlYv9waEyAPH7iqsuKx94XEDq6fRqKwJ3Z19ikafjEfkr7jd2Q5ArK48xyr5E2tVUeVkQggh8kNCQgJ9+/bl4cOH2No+/+aFqndmX9aSJUuoW7duloUswOTJkxk/fnz689jYWFxdXWnXrt0LOycvpKSkEBgYSNu2bTE3N8/36xUl0jdG9lfus+Ly0Rce187Hy/TuzGbQjcRLO+A3f2wTb9I6bAb6Vz9C32QUKKqPmFKV/CxlTfomc9IvWZO+yVxB98uT36Rnh6rFbNmyZdFqtdy6dStD+61bt3BycnruufHx8fzyyy/MmDHjucdZWlpiaWn5TLu5uXmBfkgL+npFian3jXe1cjjb6Yh+mMjz7ruG3U2gefVyKErm42tNQo127HT/jPbJW9Bc2oZ25xS04buh2zywdVE7nepM/WfpeaRvMif9kjXpm8wVVL/k5Bqq3s6wsLCgUaNG7Nq1K71Nr9eza9euDMMOMvPrr7+SlJRE//798zumEPlKq1GY6ucBwPPK1GmbzzF02RHuPDLtzQSSzW1Je30FdJkJ5lbGHcPmNYNzm9WOJoQQQgWq/25u/PjxLFq0iOXLl3P+/Hn8/f2Jj49nyJAhAAwcODDDBLEnlixZQrdu3bC3ty/oyELkuQ51nJnXvyFOdroM7c52On7o25Cpfh5YmGnYc/EOHWftZ8+FzJeuMxmKAo2HwMj94FwfHj+AtQNg02hIilM7nRBCiAKk+pjZXr16cefOHaZMmUJ0dDT169cnICAAR0dHAK5du4ZGk7HmvnjxIgcOHGDHjh1qRBYiX3So40xbDydCwm6zI+gQ7Xy88K5WDq3GeL/W282ecb+EciH6EUOWHWGgdyX+06kWOvMXTx4rtspWh2GBsPdzODATTqyEiIPQczGUb6R2OiGEEAVA9WIWYPTo0YwePTrTr+3du/eZtpo1a6LiIgxC5ButRsGrShnunTfgVaVMeiEL4O5ky8Z3mvPfgIssPXiFFSERBP91j1m961PbxU7F1CozswDfacZNFn4bBffDYUk7aD0JWowHjQkX+0IIYQJUH2YghMg+nbmWKX4eLB/aBAcbS8Jux9H9+2AW7Q9Hb0qbKmSmig/4H4DaPUCfCrs/hWVdIOaa2smEEELkIylmhSiCWtVwIGCsD209HElO0/PZ1vMMWHqI6H9sh2tySpSG15dC9wVgYQPXgmFeCzi9Tu1kQggh8okUs0IUUfbWliwc0IjPu9elhLmWg2H36DBrP9tOR6kdTV2KAp69YVQQVGgCSQ9h/TBYPwISH6qdTgghRB6TYlaIIkxRFPp6VeSPMS2oW96OmIQU/H86zsR1p4hPSlU7nrrKVIEh26D1ZFC0cHqt8S5tRPa2yhZCCFE0SDErRDHg5mDNev9m+Ld2Q1FgzdHrdJ4dROj1GLWjqUtrZpwINjQASleGh9dgWSfjeNo02XddCCGKAylmhSgmLMw0TOzgzurhTXGx03H1XgI95wUzd/dl0kx9cphrExh1ADz7gkEP+7+Cpe3h3l9qJxNCCPGSpJgVopjxdrNn29iWdKnnTJrewNc7LtF7YQg3HiSoHU1dljbQfR68/iPo7ODmMZjvA8dXgiz1J4QQRVauitnr169z48aN9OeHDx9m3LhxLFy4MM+CCSFyz87KnDl9GvDtm55YW5px5OoDOs4MYlPoTbWjqa9OD/APhso+kBIPm0fD2oGQcF/tZEIIIXIhV8Vs37592bNnDwDR0dG0bduWw4cP8+GHHzJjxow8DSiEyB1FUejRsAJbx/jQsGIpHiWlMvaXUMb+coLYRBMfL2pXAQZuAt/poDGH85thXnMI36d2MiGEEDmUq2L2zJkzNGnSBIC1a9dSp04dgoOD+emnn1i2bFle5hNCvKSK9lasHenNON/qaDUKm0Ij6TgziMNXTPxOpEYLLcbB8ECwrw6PImHFa7DjI0hNUjudEEKIbMpVMZuSkoKlpSUAO3fu5LXXXgPA3d2dqCgTX+NSiELITKthnG8N1o70pmIZK27GPKb3whC+2XGRlDS92vHU5dIARu6DxkONz4PnwOI2cOeiurmEEEJkS66K2dq1azN//nyCgoIIDAykQ4cOAERGRmJvb5+nAYUQeadRpdJsHetDz4YV0Btgzu4wXp8fwpW78WpHU5dFSejyHfT+GazsIfo0LGgJhxfJ5DAhhCjkclXMfvnllyxYsIDWrVvTp08fPD09Adi8eXP68AMhROFkbWnGN296MrdvA2x1Zpy8HkPn2UGsOXINg6kXbu6dwD8E3NpAaiJsnQCre0HcHbWTCSGEyIJZbk5q3bo1d+/eJTY2ltKlS6e3v/XWW1hZWeVZOCFE/ulSz4WGFUszfm0of4bfZ+L60+y5cIcvetSldEkLteOpx8YR+q2DwwshcApc3g7zvKHrD1CjndrphBBC/EOu7sw+fvyYpKSk9EI2IiKCmTNncvHiRcqVK5enAYUQ+celVAl+Gt6USR3dMdMoBJyNpsOs/RwMu6t2NHVpNNB0FLy1B8rVhvg7sPoN2PpvSHmsdjohhBBPyVUx27VrV1asWAFATEwMXl5efPPNN3Tr1o158+blaUAhRP7SahRGtXLjt7ebU9WhJLdik+i3+BCfbTlHUmqa2vHU5VgbRuyGpm8bnx9eCAtbG8fUCiGEKBRyVcweP34cHx8fANatW4ejoyMRERGsWLGC2bNn52lAIUTBqFvBjj/ebUE/r4oALAq6Qrfvg7l865HKyVRmroMOX0D/9WDtCHcuwKJ/QfBc0Jv4ShBCCFEI5KqYTUhIwMbGBoAdO3bQo0cPNBoNTZs2JSIiIk8DCiEKjpWFGZ91r8uigY0pU9KC81GxdJlzgJUhV2VyWDVf485hNTtDWjLs+BBWdYdYWY5QCCHUlKtitlq1amzcuJHr16+zfft22rUzToq4ffs2tra2eRpQCFHw2no4EjDOh5Y1HEhK1fPxprMMW36UO49MfDOBkmWh90/QZSaYW0H4XuPksPO/q51MCCFMVq6K2SlTpjBhwgQqV65MkyZN8Pb2Box3aRs0aJCnAYUQ6ihno2PZ4FeY6ueBhZmG3Rdu03HWfvZcuK12NHUpCjQeAiP3g3N9ePwA1vSHze9CUpza6YQQwuTkqph9/fXXuXbtGkePHmX79u3p7W3atOG7777Ls3BCCHVpNApDmldh8+jmuDvZcDcumSHLjjBl0xkSU0x8cljZ6jAsEFq8ByhwfIVxo4Wbx9ROJoQQJiVXxSyAk5MTDRo0IDIykhs3bgDQpEkT3N3d8yycEKJwcHeyZeM7zRnavAoAK0Ii8JtzgLORD1VOpjIzC/CdBoN+B9sKcP8vWNIO9n8NehMv9oUQooDkqpjV6/XMmDEDOzs7KlWqRKVKlShVqhSffPIJepndK0SxpDPXMsXPg+VDm+BgY8nl23F0/z6YRfvD0etNfHJYFR/wPwC1e4A+FXZ/Asu6QMw1tZMJIUSxl6ti9sMPP2Tu3Ln83//9HydOnODEiRN8/vnnzJkzh48//jivMwohCpFWNRwIGOtDWw9HktP0fLb1PAOWHiL6YaLa0dRVojS8vhS6LwALG7gWDPNawOl1aicTQohiLVfF7PLly1m8eDH+/v7Uq1ePevXq8fbbb7No0SKWLVuWxxGFEIWNvbUlCwc04vPudSlhruVg2D06zNpPwBkTX6ZKUcCzN4wKggpNIOkhrB8GG96CRBMfkiGEEPkkV8Xs/fv3Mx0b6+7uzv379186lBCi8FMUhb5eFfljTAvqlrcjJiGFUauOM3HdKeKTUtWOp64yVWDINmg9GRQtnFpjvEsbEaJ2MiGEKHZyVcx6enoyd+7cZ9rnzp1LvXr1XjqUEKLocHOwZr1/M/xbu6EosObodTrPDiL0eoza0dSlNYPWk2BoAJSuDA+vwbJOsPtTSEtRO50QQhQbZrk56b///S+dO3dm586d6WvMhoSEcP36dbZu3ZqnAYUQhZ+FmYaJHdxpWd2B99eGcvVeAj3nBfOeb3X8W1dDq1HUjqge1yYw6gBs/QBOrob9X8Ffu6HHIrB3UzudEEIUebm6M9uqVSsuXbpE9+7diYmJISYmhh49enD27FlWrlyZ1xmFEEWEt5s928a2pEs9Z9L0Br7ecYk+C//kxoMEtaOpy9IGus+D138EnZ1xLdr5PnBiFZj6NsFCCPGScr3OrIuLC5999hnr169n/fr1fPrppzx48IAlS5bkZT4hRBFjZ2XOnD4N+PZNT6wtzTh89T4dZwaxKfSm2tHUV6cH+AdDZR9IiYdN78DagZAgcw2EECK3cl3MCiFEVhRFoUfDCmwd40PDiqV4lJTK2F9CGfvLCWITTXy8qF0FGLgJfKeDxhzOb4Z5zSF8n9rJhBCiSJJiVgiRbyraW7F2pDfjfKuj1ShsCo2k48wgjlw18TuRGi20GAfDA8G+OjyKhBVdYcfHkJqkdjohhChSpJgVQuQrM62Gcb41WDvSm4plrLgZ85heC0L4ZsdFUtJMfMdAlwYwch80HgoYIHg2LG4Ddy6qnUwIIYqMHK1m0KNHj+d+PSYm5mWyCCGKsUaVSrN1rA9TN51l/fEbzNkdxv7Ld5nZqz5VypZUO556LEpCl++gWlvYPBqiT8OCltDuU3hluHEjBiGEEFnK0Z1ZOzu75z4qVarEwIED8yurEKKIs7Y045s3PZnbtwG2OjNOXo+h8+wg1h65jsHUZ/W7dwL/EHBrA6mJsHUCrO4FcXfUTiaEEIVaju7M/vjjj/mVQwhhQrrUc6FhxdKMXxvKn+H3+WD9KfZcvM3n3etSuqSF2vHUY+MI/dbB4YUQOAUub4d53tBtHlRvq3Y6IYQolGTMrBBCFS6lSvDT8KZM6uiOuVZh25loOszaz8Gwu2pHU5dGA01HwVt7oFxtiL8DP70OW/8NKY/VTieEEIWOFLNCCNVoNQqjWrmxwb85VR1Kcis2iX6LD/HZlnMkpaapHU9djrVhxG5o+rbx+eGFsLC1cUytEEKIdFLMCiFUV7eCHX+824J+XhUBWBR0hW7fB3P51iOVk6nMXAcdvoD+68HaEe5cgEX/gpDvQf+/lSD0aSgRByh/PwQl4gDoTfwfAUIIk6N6Mfv9999TuXJldDodXl5eHD58+LnHx8TE8M477+Ds7IylpSU1atRg69atBZRWCJFfrCzM+Kx7XRYNbEyZkhacj4qly5wDrAy5KpPDqvkadw6r2RnSkmH7f2BVdzi2HGbWwWxVNxpHzMNsVTeYWQfObVY7sRBCFBhVi9k1a9Ywfvx4pk6dyvHjx/H09KR9+/bcvn070+OTk5Np27YtV69eZd26dVy8eJFFixZRvnz5Ak4uhMgvbT0cCRjnQ8saDiSl6vl401mGLT/KnUcmvplAybLQ+yfoMhPMrSB8L/w+BmIjMx4XG2XcIlcKWiGEiVC1mP32228ZMWIEQ4YMwcPDg/nz52NlZcXSpUszPX7p0qXcv3+fjRs30rx5cypXrkyrVq3w9PQs4ORCiPxUzkbHssGvMNXPAwszDbsv3KbjrP3svWTiy1QpCjQeAiP2GLfCzdT/7mIHTJIhB0IIk5CjpbnyUnJyMseOHWPy5MnpbRqNBl9fX0JCQjI9Z/PmzXh7e/POO++wadMmHBwc6Nu3LxMnTkSr1WZ6TlJSEklJf9/RiY2NBSAlJYWUlPzfI/7JNQriWkWN9E3mpF/+1r9JBV6paMf7605z8VYcI1aewMdRg09CIjZWaqdTjxIbhZn+eZ8PA8TeJDV8P4ZKLQosV2EkP0+Zk37JmvRN5gq6X3JyHcWg0mC0yMhIypcvT3BwMN7e3untH3zwAfv27ePQoUPPnOPu7s7Vq1fp168fb7/9NmFhYbz99tuMGTOGqVOnZnqdadOmMX369GfaV69ejZWVCf9tKEQRkqKH369p2Bdl/GWSUwkDA6qnUcFENw4rfz+ExhHzXnjc0Ur+3Czj/cLjhBCisElISKBv3748fPgQW1vb5x6r2p3Z3NDr9ZQrV46FCxei1Wpp1KgRN2/e5KuvvsqymJ08eTLjx49Pfx4bG4urqyvt2rV7YefkhZSUFAIDA2nbti3m5ln9WtA0Sd9kTvolc12BPeejmfDrSaIfK8w8a877baszxLsSGo1pbfmqRNhCNorZ+rVr4NmgUwEkKrzk5ylz0i9Zk77JXEH3y5PfpGeHasVs2bJl0Wq13Lp1K0P7rVu3cHJyyvQcZ2dnzM3NMwwpqFWrFtHR0SQnJ2Nh8ezOQZaWllhaWj7Tbm5uXqAf0oK+XlEifZM56ZdnvVrLiYmex9kT58zOC3f4v4BLBIXd45s36uNkp1M7XsGp2hJsXYyTvcj6l2tmW9+D68Hw6n+gTNWCy1cIyc9T5qRfsiZ9k7mC6pecXEO1CWAWFhY0atSIXbt2pbfp9Xp27dqVYdjB05o3b05YWBj6J+srApcuXcLZ2TnTQlYIUfxYm8MPfevzefe6lDDXcjDsHh1m7SfgTJTa0QqORgsdvvzfk3/elVaMD9f//Tl6+leY+wpseR8e3UIIIYobVVczGD9+PIsWLWL58uWcP38ef39/4uPjGTJkCAADBw7MMEHM39+f+/fvM3bsWC5dusSWLVv4/PPPeeedd9R6C0IIFSiKQl+vivwxpgV1y9sRk5DCqFXHmbjuFPFJqWrHKxger8GbK8DWOWO7rYuxfVgAjAyCam1BnwpHFsPs+rDrE0h8qEpkIYTID6qOme3Vqxd37txhypQpREdHU79+fQICAnB0dATg2rVraDR/19uurq5s376d9957j3r16lG+fHnGjh3LxIkT1XoLQggVuTlYs96/Gd/tvMT8fX+x5uh1Dl25x6zeDfB0LaV2vPzn8Rq4dyY1fD+hQdup79Mes6otjXduAZzrQf91cPUA7JwGN45A0NdwdAm0GA9NRoB5CVXfghBCvCzVJ4CNHj2a0aNHZ/q1vXv3PtPm7e3Nn3/+mc+phBBFhYWZhokd3GlZ3YH314Zy9V4CPecFM863Ov6tq6Et7pPDNFoMlVpw82wsnpVa/F3IPq1yCxgWCBe3wq4Zxm1xAz+GQ/Oh9STw7Ata1f86EEKIXFF9O1shhMgL3m72bBvbki71nEnVG/h6xyX6LPyTGw8S1I5WOCgKuHc2bovbbR7YuULsTdj8LvzQFM5tAlPfNlgIUSRJMSuEKDbsrMyZ06cB377pibWlGYev3qfjzCA2hd5UO1rhodFC/b4w+ii0/wKs7OHeZeMWuIv+BeH71E4ohBA5IsWsEKJYURSFHg0rsHWMDw0rluJRUipjfwll3C8niE2UHX3SmevA+20YEwqtJoGFNUQehxWvwYpuEHlC7YRCCJEtUswKIYqlivZWrB3pzTjf6mg1ChtDI+k4M4gjV++rHa1w0dnCq5ONRa3XKNCYQ/geWNgafh0Md8NUDiiEEM8nxawQotgy02oY51uDtSO9qVjGipsxj+m1IIRvdlwkJU3/4hcwJdYO0PFLePcYePYBFDj7G3zfBH4fC7GRaicUQohMSTErhCj2GlUqzdaxPvRsWAG9AebsDuP1+SFcvRuvdrTCp3Ql6D4f/A9CjY5gSINjy2B2AwicCo8fqJ1QCCEykGJWCGESrC3N+OZNT+b2bYCtzoyT12PoNDuItUeuY5BZ/M9yrA19f4Gh26GiN6QmwsGZMMsTgr6FZFklQghROEgxK4QwKV3quRAwriVNq5YhITmND9af4u2fjvMgPlntaIVTxaYwZBv0XQvlaht3D9s13Xin9uhSSJNJdUIIdUkxK4QwOS6lSvDT8KZM6uiOuVZh25loOszaz8Gwu2pHK5wUBWq0h1FB0H0hlKoIcdHwx3vGMbVn1oNexiALIdQhxawQwiRpNQqjWrmxwb85VR1Kcis2iX6LD/H51vMkpaapHa9w0mjBsxeMPgYdv4KSDnA/HNYNhUWtIWyXbLwghChwUswKIUxa3Qp2/PFuC/p5VQRg4f5wun8fTNjtRyonK8TMLMDrLeNyXq9+CBY2EHUSVvWA5X5w46jaCYUQJkSKWSGEybOyMOOz7nVZNLAxZUpacC4qls6zD7Ay5KpMDnseS2to9QGMPQneo0FrAVeDYHEb+KUf3LmodkIhhAmQYlYIIf6nrYcjAeN8aFnDgaRUPR9vOsuw5Ue5G5ekdrTCraQ9tP8M3j0O9fuDooELf8APTWHTO/DwhtoJhRDFmBSzQgjxlHI2OpYNfoWpfh5YmGnYfeE2HWbuZ8+F22pHK/xKuUK378E/BNy7gEEPJ1bB7Iaw/UNIkN3XhBB5T4pZIYT4B41GYUjzKmwe3Rx3JxvuxiUzZNkRpmw6Q2KKTA57oXLu0PsnGLYTKvtAWhKEzDWuUbvvK0iKUzuhEKIYkWJWCCGy4O5ky8Z3mjO0eRUAVoRE4DfnAGcjH6qcrIhwfQUG/Q7914NTPUiKhT2fwuz6cGghpMravkKIlyfFrBBCPIfOXMsUPw+WD22Cg40ll2/H0f37YBYHhaPXy+SwF1IUqOYLb+2D15dCmaoQfwe2/RvmNoZTa2WNWiHES5FiVgghsqFVDQcCxvrQ1sOR5DQ9n245z8Clh4l+mKh2tKJBo4E6PeGdw9D5W7B2hJgI2DACFvjApe2yRq0QIlekmBVCiGyyt7Zk4YBGfN69LiXMtRwIu0uHWfsJOBOldrSiQ2sOrwyDMSegzVSwtINbZ2D1m/BjJ7j2p9oJhRBFjBSzQgiRA4qi0NerIn+MaUHd8nbEJKQwatVxJq47RXxSqtrxig6LkuAzHsaGQvOxYKaDa8GwtD2s7g23zqqdUAhRREgxK4QQueDmYM16/2b4t3ZDUWDN0et0nh3EyesxakcrWqzKQNsZxju1jQaDooVL22Bec/htFDyIUDuhEKKQk2JWCCFyycJMw8QO7qwe3hQXOx1X7yXQc14wc3dfJk0mh+WMrQv4zYJ3DoFHN8AAJ3+GOY1g20SIu6N2QiFEISXFrBBCvCRvN3u2jW1Jl3rOpOoNfL3jEn0W/smNBwlqRyt6ylaHN5fDiD1Q9VXQp8Ch+cblvPZ8AYmxaicUQhQyUswKIUQesLMyZ06fBnz7pifWlmYcvnqfjjOD2BR6U+1oRVP5hjBwIwzcBC4NIDkO9v2fsagN+QFSZYthIYSRFLNCCJFHFEWhR8MKbB3jQ8OKpXiUlMrYX0IZ98sJYhNT1I5XNFVtbbxL++YKsK8OCfdg+2Tj8IPQ1aCXHdmEMHVSzAohRB6raG/F2pHejPOtjlajsDE0ko4zgzhy9b7a0YomRQGPrvD2n+A3G2xc4OF12OgP85rBhS2yRq0QJkyKWSGEyAdmWg3jfGuwdqQ3FctYcTPmMb0WhPDNjoukpMmOV7miNYNGg2DMcWj7CehKwZ0L8EtfWNIOrh5UO6EQQgVSzAohRD5qVKk0W8f60LNhBfQGmLM7jNfnh3D1brza0You8xLQfAyMPQk+74O5Fdw4DMs6warXIeqU2gmFEAVIilkhhMhn1pZmfPOmJ3P7NsBWZ8bJ6zF0mh3E2iPXMcivx3OvRCloM8W4Ru0rw0FjBmGBxu1x1w2D++FqJxRCFAApZoUQooB0qedCwLiWNK1ahoTkND5Yf4q3fzrOg/hktaMVbTZO0PkbGH0E6rxubDuzDua+gibgAyxTYlSNJ4TIX1LMCiFEAXIpVYKfhjdlUkd3zLUK285E02HWfg6G3VU7WtFXpiq8vgRGBkG1tqBPRXtsKb7nJqDZ8xkkPlQ7oRAiH0gxK4QQBUyrURjVyo0N/s2p6lCSW7FJ9Ft8iM+3nicpVZaaemnO9aD/Ohi8BX35xpjpk9EGfwezPOHgbEh5rHZCIUQekmJWCCFUUreCHX+824J+XhUBWLg/nO7fBxN2+5HKyYqJyi1IG7SNQ1XGYihbEx4/gMCPYXZDOLYc0lLVTiiEyANSzAohhIqsLMz4rHtdFg1sTJmSFpyLiqXz7AOsDLkqk8PygqIQXaoRqSP2Q7d5YOcKjyLh9zHwQ1M4t0nWqBWiiJNiVgghCoG2Ho4EjPOhZQ0HklL1fLzpLMOWH+VunGzbmic0WqjfF0YfhfZfgJU93LsMawfCon9B+F61EwohckmKWSGEKCTK2ehYNvgVpvp5YGGmYfeF23SYuZ89F26rHa34MNeB99swJhRaTQILa4g8Diu6wopuEHlC7YRCiBySYlYIIQoRjUZhSPMqbB7dHHcnG+7GJTNk2RGmbDpDYopMDsszOlt4dbKxqPUaBRpzCN8DC1vD2kFwN0zthEKIbJJiVgghCiF3J1s2vtOcoc2rALAiJAK/OQc4FxmrcrJixtoBOn4J7x4Dzz6AAuc2wvdN4PexEBupdkIhxAtIMSuEEIWUzlzLFD8Plg9tgoONJZdvx9Ht+4MsDgpHrzdOWkrTGzh05T7H7iocunKfNL1MZsqV0pWg+3zwPwg1OoIhDY4tg9kNIHAKJNxXO6EQIguFopj9/vvvqVy5MjqdDi8vLw4fPpzlscuWLUNRlAwPnU5XgGmFEKJgtarhQMBYH9p6OJKcpufTLecZuPQwPx++Rosvd9N/6VFWXNbSf+lRWny5m4AzUWpHLroca0PfX2DodqjoDamJcHAWzK4PQd9CcoLaCYUQ/6B6MbtmzRrGjx/P1KlTOX78OJ6enrRv357bt7Oe8GBra0tUVFT6IyIiogATCyFEwbO3tmThgEZ83r0uJcy1HAi7y+QNp4l6mJjhuOiHifivOi4F7cuq2BSGbIO+a6FcbePuYbumG+/UHlkCaSlqJxRC/I/qxey3337LiBEjGDJkCB4eHsyfPx8rKyuWLl2a5TmKouDk5JT+cHR0LMDEQgihDkVR6OtVkU2jm2OuUTI95skgg+m/n5MhBy9LUaBGexh1AHosglKVIC4atow3jqk9sx70erVTCmHyzNS8eHJyMseOHWPy5MnpbRqNBl9fX0JCQrI8Ly4ujkqVKqHX62nYsCGff/45tWvXzvTYpKQkkpL+XqcxNtY4eSIlJYWUlPz/l/WTaxTEtYoa6ZvMSb9kTfrG6PbDBFKeU6gagKiHiYSE3carSpmCC1YI5dlnplZ3qNEZzfEVaA5+g3I/HNYNxeD4HWmvfoyh6qvG4reIkJ+lrEnfZK6g+yUn11EMKm4xExkZSfny5QkODsbb2zu9/YMPPmDfvn0cOnTomXNCQkK4fPky9erV4+HDh3z99dfs37+fs2fPUqFChWeOnzZtGtOnT3+mffXq1VhZWeXtGxJCiAJw7K7CisvaFx7Xq2oazRzl7mxe06Yl4nZnO9VubcFcbxzmcce6Fudd3uRBSTeV0wlRPCQkJNC3b18ePnyIra3tc48tcsXsP6WkpFCrVi369OnDJ5988szXM7sz6+rqyt27d1/YOXkhJSWFwMBA2rZti7m5eb5fryiRvsmc9EvWpG+MDl25T/+lR194nFYD/6pZjtc8nXm1RlkszV9cABc3+fqZSbiHJngmmqNLUdKMf8/oa3YmrfWHULZG3l4rj8nPUtakbzJX0P0SGxtL2bJls1XMqjrMoGzZsmi1Wm7dupWh/datWzg5OWXrNczNzWnQoAFhYZkvcG1paYmlpWWm5xXkh7Sgr1eUSN9kTvola6beN97VyuFspyP6YSJZ3Y0w0yik6g0Enr9N4Pnb2OjM6FjHiW71y+NV1R5tFmNui6t8+czYOUHH/wPvd2Dv/8HJ1WgubkFzaRt49oXWk6CUa95eM4+Z+s/S80jfZK6g+iUn11B1ApiFhQWNGjVi165d6W16vZ5du3ZluFP7PGlpaZw+fRpnZ+f8iimEEIWKVqMw1c8DgH+WpMr/HnP7NmDbWB9GtqqKs52OR4mprD16g76LD9Hs/3bx2ZZznLn5EBV/OVd8lHKFbt+Dfwi4dwGDHkJXwZxGsP1DiL+ndkIhijVV78wCjB8/nkGDBtG4cWOaNGnCzJkziY+PZ8iQIQAMHDiQ8uXL88UXXwAwY8YMmjZtSrVq1YiJieGrr74iIiKC4cOHq/k2hBCiQHWo48y8/g2Z/vu5DMtzOdnpmOrnQYc6xn/g13K2ZWJ7dw5fvc+m0Ei2no7iVmwSi4KusCjoCm4OJelWvzxd65enor3MI3gp5dyh909w/YhxGa+rQRAyF44th+ZjoOnbYGmtdkohih3Vi9levXpx584dpkyZQnR0NPXr1ycgICB9ua1r166h0fx9A/nBgweMGDGC6OhoSpcuTaNGjQgODsbDw0OttyCEEKroUMeZth5OhITdZkfQIdr5eOFdrdwzQwg0GoWmVe1pWtWeaa95sO/iHTaFRrLz/C3+uhPPN4GX+CbwEg0rlqJbg/J0ruuMvfWzw7NENrm+AoN+h792wc7pEH0K9nwGhxdCyw+g0WAws1A7pRDFhurFLMDo0aMZPXp0pl/bu3dvhuffffcd3333XQGkEkKIwk+rUfCqUoZ75w14VSnzwrGwlmZa2tV2ol1tJx4lphBwJprNJyM5GHaX49diOH4thum/n8Onelm61S9Pu9qOWFkUir8qihZFgWq+UPVfcO432P0p3A+Hbf823q199UOo+wZoVF/uXYgiT/6EEkIIE2WjM+eNxq680diV27GJ/H4qik2hNzl14yF7L95h78U7lDDX0q62I93ql6dF9bKYa6X4yhGNBur0hFqvwfEVsO9LiImA396C4NnQZgpUb1ek1qgVorCRYlYIIQTlbHUMa1GFYS2q8NedODaFRrIp9CYR9xL+9/+RlClpQee6znRr4ELDiqVRpADLPq05vDIMPHvDoQVwYCbcOgOr34SK3uA7zbiFrhAix6SYFUIIkYGbgzXj29bgPd/qnLzxkI0nbvLHqUjuxiWz8s8IVv4ZgWuZEnT1LE+3Bi5UK2ejduSiw6Ik+Iw3jps9ONNY2F4LgaXtoUZHaPMxOGa+o6UQInNSzAohhMiUoijUdy1FfddSfNS5Fgf/usemEzfZfjaa6/cfM3dPGHP3hOHhbEu3Bi685lkeJzud2rGLBqsy0HYGeI0yDj04vhIubYNLAVCvF7w6GUpXVjulEEWCFLNCCCFeyEyroVUNB1rVcOBxcho7z99iU+hN9l68w7moWM5FxfLFtgs0rWJPtwYudKjjjF0JWXD+hWxdwG8WeI82ThI7txFO/QJn1huHJfhMAGsHtVMKUahJMSuEECJHSlho8fN0wc/ThQfxyWw5bZw4duTqA0LC7xESfo+PN57lVXcHutUvz6vu5dCZ4Fa6OVK2Ory5HG4eh10zIHwPHJpvvGPbbLSx2NXl/xbsQhRFUswKIYTItdIlLejftBL9m1bi+v0Efj8VyaYTkVy89YjtZ2+x/ewtk99KN0fKN4SBGyF8L+ycBpEnjMMQjiw23qVtPBTMZSiHEE+TYlYIIUSecC1jxdutq/F262qcj4plY+hNNodGEvUwkbVHb7D26A0cbS15zdOFrvXLU9vFVlZEyErV1jBiD5zfDLs+gXuXYftk+PMHaD3ZuCqCRu52CwFSzAohhMgHtZxtZSvdl6Uo4NEVanaG0J9g7//Bw+uw6e2/16it2UnWqBUmT1a/FkIIkW+ebKX7RY+6HP6wDQsHNKJzXWcszTTpW+m2/GoPPX44yIqQq9yLS1I7cuGjNYNGg2DMcWj7CehKwZ0L8EtfWNIWrh5QO6EQqpI7s0IIIQqEbKX7ksxLQPMx0HCg8c7sn/PgxhFY1tm4dW6bqeBcT+2UQhQ4+VNCCCFEgZOtdF9CiVLGIQZN3oL9X8GxZRC20/io8zq8+h+wd1M7pRAFRopZIYQQqpKtdHPJxgk6fwPe78Duz+DMOuPj3EZoOAhafWA8RohiTv6ZK4QQotB4spXu3gmt2fhOcwY3q0xZawvuxxu30u05L4SWX+3h6+0XCbv9SO24hUOZqvD6EhgZBNXagj4Vji6B2Q2Ma9Y+jsl4vD4NJeIA5e+HoEQcAH2aKrGFyCtyZ1YIIUShI1vp5oJzPei/zjghbOc043jaoG/gyBLwGW8clnA5EAImYhYbSWOAiHnGXcg6fAker6n8BoTIHSlmhRBCFGqylW4OVW4BwwLh4lbjndk7FyBwCgR9B4kPnj0+NgrWDoQ3V0hBK4okKWaFEEIUGdnaSnfTWf5VsxzdGrjQompptSOrQ1HAvTPU6ACn1hjH1MbeyOJgA6BAwCTjObIZgyhipJgVQghRJD29le6NBwlsPvn3VroBZ6MJOBuNjc4MDxsNpcPv0by6o+ltpavRQv2+YO0Iq3o850ADxN6EiGCo4lNg8YTIC1LMCiGEKPIqlM56K91DiRoO/XjMtLfSfZzJ8ILMPIiQYlYUOVLMCiGEKFae3ko3OOw2P/xxmLOPLEx7K11rx+wdt2U8hO+Bem+C279Aa8Jjj0WRIcWsEEKIYkmjUfCqUoZ7bnratGtNcPgDNoVGsvP8rfStdL8JvETDiqXo1qA8nes6Y29tqXbs/FGpmXHVgtgojGNkM6FoIS3p7/Vqreyhdneo+ya4NjGOwxWiEJJiVgghRLFnaaYx7a10NVrj8ltrBwIKGQva/xWpb/wIthXg9Fo4sx7i78CRxcZHqYpQ9w1jYVvOXYU3IETWitFPqhBCCPFiJruVrsdrxuW3AiZCbOTf7bYu0OH//l6Wq0IjaPcZXNkLp36FC39AzDXjmrVB34BTXWNRW/d147lCqEyKWSGEECYru1vpdqnnTNf6xWArXY/XwL0zqeH7CQ3aTn2f9phVbfnsclxaM6jma3wkJ8ClbcbCNiwQok8bH4FTjGva1nsTar0GJUqp8paEkGJWCCGE4O+tdN/zrc7JGw/ZeOImf5yK5G5cMitCIlgREoFrmRJ09SxPtwYuVCtno3bk3NFoMVRqwc2zsXhWavHidWUtrKBOT+Mj4T6c/Q1O/wrXQuBqkPGx5X2o3s5Y2FZvD+YmvhubKFBSzAohhBBPye5WurVdbOlWvzx+ni6ms5WuVRl4ZZjxEXMNTq8zFra3zxmHI1z4AyztwMPPOBShcjaKZSFekhSzQgghRBaet5Xu2chYzkbG8vm286a5lW6piuAz3viIPmOcOHZ6vXGnsROrjA8bZ+Md3bpvgLOnrIgg8oUUs0IIIUQ25HQr3dY1y6EzN5G7kk51jI8204zDD06vhbMb4VEUhMw1PsrW+HviWJkqaicWxYgUs0IIIUQOZXcr3Y51nOhWvzxeVe1NYytdjQYqNzc+Ov4XwnbCqbVwKQDuXoI9nxofFV4xFrZ1ekDJsmqnFkWcFLNCCCHES8hsK93fQyOJfJjI2qM3WHv0hmlupWtmCe6djY/EWON42lNr4co+uHHE+AiYZNxprN6bULMTWFqrnVoUQVLMCiGEEHnk6a10j1y9z8bQSLaejjLtrXQBdLZQv6/x8SgazmwwDkWIPGFc7issEMytjIVv3TdkK12RI1LMCiGEEHlMo1HwqmqPV1V7pr3mwb6Ld0x3K91/snEC77eNj7thxtUQTq+F++H/+/9fZStdkSNSzAohhBD5yNJMm62tdFtWL0vX4riV7vOUrQavTobWk+Dm8Sy20q30v61035CtdEWmTOSnRQghhFDf87bS3XPxDnuK61a6L6Ioxm10M91KNwKCvjY+ZCtdkQkpZoUQQggVmNxWutklW+mKHJJiVgghhFCZyWylm1Oyla7IBilmhRBCiEJCttJ9DtlKV2RBilkhhBCiEJKtdJ9DttIVT5FiVgghhCjk8nIr3TS9gUNX7nPsroL9lft4VytXtHcnk610TV6hmCL5/fffU7lyZXQ6HV5eXhw+fDhb5/3yyy8oikK3bt3yN6AQQghRSDzZSvfXUc04MPFVPuhQk5qONiSn6gk4G82oVcd55bOdfLDuJMFhd0nTG9LPDTgTRYsvd9N/6VFWXNbSf+lRWny5m4AzUSq+ozzyZCtdv1kw4RL0Xg0e3cBM9/dWurPrw+K2cGghxN9VO7HII6rfmV2zZg3jx49n/vz5eHl5MXPmTNq3b8/FixcpV65cluddvXqVCRMm4OPjU4BphRBCiMIjJ1vpOlhb8sW2Cxj+8RrRDxPxX3Wcef0b0qGOsyrvI889dyvdw8aHbKVbbKhezH777beMGDGCIUOGADB//ny2bNnC0qVLmTRpUqbnpKWl0a9fP6ZPn05QUBAxMTEFmFgIIYQofF60lW5WDIACTP/9HG09nIr2kIPM5Ggr3TehYgu1E4scUrWYTU5O5tixY0yePDm9TaPR4OvrS0hISJbnzZgxg3LlyjFs2DCCgoKee42kpCSSkpLSn8fGxgKQkpJCSkrKS76DF3tyjYK4VlEjfZM56ZesSd9kTvola6baNw1dbWnoasuHHWsQdPkuPwZHcPjqgyyPNwBRDxMJCbuNV5UyBRe0oOnsofEI4+NeGJqz69GcWYfy4Er6VrpmJcpQr2QD0q6WgkreMnHsfwr6Zykn11G1mL179y5paWk4OjpmaHd0dOTChQuZnnPgwAGWLFlCaGhotq7xxRdfMH369Gfad+zYgZWVVY4z51ZgYGCBXauokb7JnPRL1qRvMif9kjVT7xt3c4XDvHiZqi37DnHv/D8HIhRndaFSHUo5hFPhQQjlH/yJ7vF9qjzeBT/tIt7CgRulvblRxps4XXm1wxYKBfWzlJCQkO1jVR9mkBOPHj1iwIABLFq0iLJly2brnMmTJzN+/Pj057Gxsbi6utKuXTtsbW3zK2q6lJQUAgMDadu2LebmJrJkSjZJ32RO+iVr0jeZk37JmvSNkf2V+6y4fPSFx62/akZcSUde83SmuZu9aWylm+5d0KeSGLabOzu/p0JcKCWT71Dz1mZq3tqMwbEu+jo90Xv0BNtiMrY4Bwr6Z+nJb9KzQ9VitmzZsmi1Wm7dupWh/datWzg5OT1z/F9//cXVq1fx8/NLb9Pr9QCYmZlx8eJF3NzcMpxjaWmJpaXlM69lbm5eoH+wFfT1ihLpm8xJv2RN+iZz0i9ZM/W+8a5WDmc7HdEPE5+ZAPaEVqOQnGbg91PR/H4q2jS30sUcarTjeFgqTm1bYx6+M30rXeXWabS3TqPdNd2kt9ItqJ+lnFxD1WLWwsKCRo0asWvXrvTltfR6Pbt27WL06NHPHO/u7s7p06cztH300Uc8evSIWbNm4erqWhCxhRBCiCJFq1GY6ueB/6rjKJChoH1Sos7t0wDnUiVkK90nzGUr3aJC9WEG48ePZ9CgQTRu3JgmTZowc+ZM4uPj01c3GDhwIOXLl+eLL75Ap9NRp06dDOeXKlUK4Jl2IYQQQvytQx1n5vVvyPTfzxH1MDG93clOx1Q/j/RluWQr3UzIVrqFmurFbK9evbhz5w5TpkwhOjqa+vXrExAQkD4p7Nq1a2g0pjRmRwghhMgfHeo409bDiZCw2+wIOkQ7H69MdwCTrXSfQ7bSLXRUL2YBRo8enemwAoC9e/c+99xly5blfSAhhBCimNJqFLyqlOHeeQNeVcq8cF3ZvNxKt9iRrXQLhUJRzAohhBCi8HuylW7/ppW48SCBzScj2XQikou3HhFwNpqAs9HY6MzoWMeJbvXL41XVvvhtwpCZJ1vpVm4OHf8LYTuNO45dCvh7K909n0KFJsbxtbW7Q8nsrcokXkyKWSGEEELkWE620u1avzy1XWxNY0WE7Gylu22ibKWbh6SYFUIIIcRLedFWuouCrlCtnDVd/1fYVrQvuE2LVJXTrXTdXgWtiYw9zkNSzAohhBAiT2g0Cl5V7f+/vbsPiuo+9wD+XZDlTUCRV5GgCIJgkKgJhWjFoICxGnLNSFo0RG3TKGTwmjbBtBG48V51xmg6U4NWiyba1mpuNcYqBjFgRFREUFRCfSFowqs14c1IuPC7fxA2LuzyJrtnD+f7mdkZ9uzvsM958jjz5HDOeRDiPQqpCwKQW1aHj4srcaK0Bjdqm/Bu1r/wbta/MOWxEYh5wgPzHnfHqOHdnwU/JNm5AaErO153b/wwPnc/cO+WZpQubEZ1XILw+CLA8yneONZHbGaJiIho0FkOM0dkoBsiA93Q+KAVx692PBEh78ZdXLz9LS7e/hZpn1zDT32d8FywByIDXWGjVkhb4uQDzFoDhCcDX1/saGqv/C/QXAcU7Ox4jfDqeBpC0CLA2U/qiE2aQqqGiIiIpGJnZYEXpo7BC1PHoLbhAT653PFEhMtf1eOzsjp8VlYHawtzRAa6IibYA9N9nZQxSlelAsZM7XhF/jdQntMxceyLI8C3FcDnmzpebo//+EQE+9FSR21y2MwSERGR0bjYW2H59HFYPn0cbtU14ePiSnxc/DW+/Pf9H36uVOYoXfNhgM/sjtf394F/HdOM0kV1Sccra62iR+nqw2aWiIiIJOHtPBz/OWcCVs32xaWv6jlKt5Oao3T7g80sERERSUqlUiHYcwRH6erCUbq9YjNLREREJoOjdHvAUbo6sZklIiIik8RRuj3gKF0NNrNERERk8jhKVw+O0mUzS0RERPLCUbp69HeUrv88QG0rddSPjM0sERERyVZfRumOd7ZFTLAHR+kOdJRuextUFafhcS8fqgp7wPunJnWTGZtZIiIikr2eRunerGvmKN2BjtK9dhjIfBPDGioxDQAq0jsGN0RvBAIWSHlUGmxmiYiIaEjhKN0e9GeUrq0zkJkMQGj/joYqYP9LwKIPTaKhVch/OSIiIlKi/o7SDRnrIHXIxtGXUbp6CQCqjkbXf57klxywmSUiIiJF6Mso3ZE2FphkZwa329/iKW8nZdw4pmuU7tltHTeM6SWAhq+BijPAuBlGC1UXNrNERESkOD2N0v38vhk+33Fe2aN0heilmf1BU43hY+oFm1kiIiJSrK6jdE+V1SD96AVca7BQ9ijd4a6Du86A2MwSERERoWOU7gxfJzT6tmPW7HDk3rin3FG6XmEdTy1oqEK3G8AAAKqOz73CjB1ZN2xmiYiIiLpQ/ChdM/OOx2/tfwmACtoN7Q/XEUdvkPzmL4DNLBEREVGPFDtKN2BBx+O3Mt8EGip/3G4/uqORNYHHcgFsZomIiIj6THGjdAMWAP7z8H+3TqH48+MInhGFYZwARkRERCR/ihmla2YO4TUdX19twGSv6SbVyAJsZomIiIgeCUfpSovNLBEREdEg6eso3Rm+TohR2ihdA2H2iIiIiAygp1G6OWV1yOkySne6rxMszM2kDlt22MwSERERGVhfRuk62qrxsyB3PBc8GlMeGynvG8eMiM0sERERkRH1NEr3w/wKfJhfocxRugPEZpaIiIhIAl1H6ebd/Dc+Lvoax69WK3uUbj+xmSUiIiKS2DBzM8yc4IyZE5zx3fdtOFFao9xRuv3EZpaIiIjIhCh+lG4/sZklIiIiMlGKHaXbD2xmiYiIiGRAcaN0+4jNLBEREZHMKGaUbh+wmSUiIiKSKY7SZTNLRERENCQodZSu/I+AiIiIiLQM5ijdtnaBc+X3UHhXhVHl9xDq42JSN5mZxADgrVu3YuzYsbCyskJISAjOnz+vd+0//vEPTJs2DSNGjICtrS2Cg4OxZ88eI0ZLREREJB+do3QPJ07HyddnIinCF2NH2eC71jZ8XFyJpbsLEPI/2Xj70BUUVtyDEEKzb+aVKkzfeBKLMy7gw+vmWJxxAdM3nkTmlSoJj0ib5Gdm//73v2P16tXYtm0bQkJC8N577yEqKgplZWVwcXHptt7R0RG/+93v4O/vD7VajSNHjmDp0qVwcXFBVFSUBEdAREREJA89jdLdc7YCe87+OEp31HA1/uuTaxBdfkd1/QOs2HsR6YunIHqSuyTH8TDJz8xu3rwZv/rVr7B06VIEBARg27ZtsLGxQUZGhs714eHheP755zFx4kSMHz8eSUlJCAoKwunTp40cOREREZE8dY7STV0QiLNrIvDBsqfwH094wFZtrhmlm6ajkQWg2Zb2yTW0tetaYVySnpn9/vvvUVhYiDVr1mi2mZmZYfbs2cjPz+91fyEETp48ibKyMmzcuFHnmpaWFrS0tGjeNzQ0AABaW1vR2tr6iEfQu87vMMZ3yQ1zoxvzoh9zoxvzoh9zoxvzop9ScxM2bgTCxo1A6s/8cbKsDh/kV6DoTr3e9QJAVf0D5N+oRcg4x0GPpz/5V4mHL4wwssrKSnh4eODMmTMIDQ3VbH/jjTeQm5uLc+fO6dyvvr4eHh4eaGlpgbm5Od5//30sW7ZM59rU1FSkpaV12/7Xv/4VNjZD95lrRERERANVeFeFD6/3PiL3Jd82THUa/Fby/v37+MUvfoH6+nrY29v3uFbya2YHws7ODsXFxWhqakJ2djZWr14Nb29vhIeHd1u7Zs0arF69WvO+oaEBnp6eiIyM7DU5g6G1tRVZWVmYM2cOLCwsDP59csLc6Ma86Mfc6Ma86Mfc6Ma86MfcdBhVfg8fXr/Q67rIGSEGOTPb+Zf0vpC0mXVycoK5uTlqamq0ttfU1MDNzU3vfmZmZvDx8QEABAcHo7S0FOvXr9fZzFpaWsLSsvvDgS0sLIxapMb+PjlhbnRjXvRjbnRjXvRjbnRjXvRTem5CfVzg7mCF6voHOq+bVQFwc7Ay2GO6+pN7SW8AU6vVmDp1KrKzszXb2tvbkZ2drXXZQW/a29u1roslIiIiooEzN1MhZX4AgI7G9WGd71PmB5jE82Ylf5rB6tWrsWPHDnzwwQcoLS3FihUr0NzcjKVLlwIAXnrpJa0bxNavX4+srCzcunULpaWlePfdd7Fnzx4sXrxYqkMgIiIiGnKiJ7kjffEUuDlYaW13c7AymcdyASZwzWxsbCzq6uqwdu1aVFdXIzg4GJmZmXB1dQUA3L59G2ZmP/bczc3NWLlyJb766itYW1vD398fe/fuRWxsrFSHQERERDQkRU9yx5wAN+TfqMWnn59D5IwQk5sAJnkzCwCJiYlITEzU+VlOTo7W+3Xr1mHdunVGiIqIiIiIzM1UCBnniH+XCoSMczSpRhYwgcsMiIiIiIgGis0sEREREckWm1kiIiIiki02s0REREQkW2xmiYiIiEi22MwSERERkWyxmSUiIiIi2WIzS0RERESyxWaWiIiIiGSLzSwRERERyZZJjLM1JiEEAKChocEo39fa2or79++joaEBFhYWRvlOuWBudGNe9GNudGNe9GNudGNe9GNudDN2Xjr7tM6+rSeKa2YbGxsBAJ6enhJHQkREREQ9aWxshIODQ49rVKIvLe8Q0t7ejsrKStjZ2UGlUhn8+xoaGuDp6Yk7d+7A3t7e4N8nJ8yNbsyLfsyNbsyLfsyNbsyLfsyNbsbOixACjY2NGD16NMzMer4qVnFnZs3MzDBmzBijf6+9vT3/UejB3OjGvOjH3OjGvOjH3OjGvOjH3OhmzLz0dka2E28AIyIiIiLZYjNLRERERLLFZtbALC0tkZKSAktLS6lDMTnMjW7Mi37MjW7Mi37MjW7Mi37MjW6mnBfF3QBGREREREMHz8wSERERkWyxmSUiIiIi2WIzS0RERESyxWaWiIiIiGSLzewjOnXqFObPn4/Ro0dDpVLh0KFDve6Tk5ODKVOmwNLSEj4+Pti9e7fB4zS2/uYlJycHKpWq26u6uto4ARvJ+vXr8eSTT8LOzg4uLi6IiYlBWVlZr/sdOHAA/v7+sLKywuOPP46jR48aIVrjGkhudu/e3a1mrKysjBSxcaSnpyMoKEjzoPLQ0FAcO3asx32UUC9A/3OjhHrRZcOGDVCpVFi1alWP65RSN536khel1Exqamq34/T39+9xH1OqFzazj6i5uRmTJ0/G1q1b+7S+vLwc8+bNw6xZs1BcXIxVq1bhl7/8JY4fP27gSI2rv3npVFZWhqqqKs3LxcXFQBFKIzc3FwkJCTh79iyysrLQ2tqKyMhINDc3693nzJkz+PnPf47ly5ejqKgIMTExiImJwZUrV4wYueENJDdAxzSah2umoqLCSBEbx5gxY7BhwwYUFhbiwoULeOaZZ/Dcc8/h6tWrOtcrpV6A/ucGGPr10lVBQQG2b9+OoKCgHtcpqW6AvucFUE7NBAYGah3n6dOn9a41uXoRNGgAiIMHD/a45o033hCBgYFa22JjY0VUVJQBI5NWX/Ly2WefCQDim2++MUpMpqK2tlYAELm5uXrXLFq0SMybN09rW0hIiPj1r39t6PAk1Zfc7Nq1Szg4OBgvKBMxcuRIsXPnTp2fKbVeOvWUG6XVS2Njo/D19RVZWVli5syZIikpSe9aJdVNf/KilJpJSUkRkydP7vN6U6sXnpk1svz8fMyePVtrW1RUFPLz8yWKyLQEBwfD3d0dc+bMQV5entThGFx9fT0AwNHRUe8apdZMX3IDAE1NTfDy8oKnp2evZ+Xkrq2tDfv27UNzczNCQ0N1rlFqvfQlN4Cy6iUhIQHz5s3rVg+6KKlu+pMXQDk1c/36dYwePRre3t6Ii4vD7du39a41tXoZJsm3Klh1dTVcXV21trm6uqKhoQHfffcdrK2tJYpMWu7u7ti2bRumTZuGlpYW7Ny5E+Hh4Th37hymTJkidXgG0d7ejlWrVuHpp5/GpEmT9K7TVzND7Xrih/U1N35+fsjIyEBQUBDq6+uxadMmhIWF4erVqxgzZowRIzaskpIShIaG4sGDBxg+fDgOHjyIgIAAnWuVVi/9yY1S6gUA9u3bh4sXL6KgoKBP65VSN/3Ni1JqJiQkBLt374afnx+qqqqQlpaGGTNm4MqVK7Czs+u23tTqhc0smQQ/Pz/4+flp3oeFheHmzZvYsmUL9uzZI2FkhpOQkIArV670eF2SUvU1N6GhoVpn4cLCwjBx4kRs374d77zzjqHDNBo/Pz8UFxejvr4eH330EeLj45Gbm6u3aVOS/uRGKfVy584dJCUlISsra0jerDRQA8mLUmpm7ty5mp+DgoIQEhICLy8v7N+/H8uXL5cwsr5hM2tkbm5uqKmp0dpWU1MDe3t7xZ6V1eepp54aso1eYmIijhw5glOnTvX6f/f6asbNzc2QIUqmP7npysLCAk888QRu3LhhoOikoVar4ePjAwCYOnUqCgoK8Ic//AHbt2/vtlZp9dKf3HQ1VOulsLAQtbW1Wn/Vamtrw6lTp/DHP/4RLS0tMDc319pHCXUzkLx0NVRrpqsRI0ZgwoQJeo/T1OqF18waWWhoKLKzs7W2ZWVl9XiNl1IVFxfD3d1d6jAGlRACiYmJOHjwIE6ePIlx48b1uo9SamYguemqra0NJSUlQ65uumpvb0dLS4vOz5RSL/r0lJuuhmq9REREoKSkBMXFxZrXtGnTEBcXh+LiYp0NmxLqZiB56Wqo1kxXTU1NuHnzpt7jNLl6keS2syGksbFRFBUViaKiIgFAbN68WRQVFYmKigohhBDJycliyZIlmvW3bt0SNjY24re//a0oLS0VW7duFebm5iIzM1OqQzCI/uZly5Yt4tChQ+L69euipKREJCUlCTMzM3HixAmpDsEgVqxYIRwcHEROTo6oqqrSvO7fv69Zs2TJEpGcnKx5n5eXJ4YNGyY2bdokSktLRUpKirCwsBAlJSVSHILBDCQ3aWlp4vjx4+LmzZuisLBQvPjii8LKykpcvXpVikMwiOTkZJGbmyvKy8vF5cuXRXJyslCpVOLTTz8VQii3XoTof26UUC/6dL1rX8l187De8qKUmnn99ddFTk6OKC8vF3l5eWL27NnCyclJ1NbWCiFMv17YzD6izkdKdX3Fx8cLIYSIj48XM2fO7LZPcHCwUKvVwtvbW+zatcvocRtaf/OyceNGMX78eGFlZSUcHR1FeHi4OHnypDTBG5CunADQqoGZM2dq8tRp//79YsKECUKtVovAwEDxz3/+07iBG8FAcrNq1Srx2GOPCbVaLVxdXcWzzz4rLl68aPzgDWjZsmXCy8tLqNVq4ezsLCIiIjTNmhDKrRch+p8bJdSLPl2bNiXXzcN6y4tSaiY2Nla4u7sLtVotPDw8RGxsrLhx44bmc1OvF5UQQhjvPDARERER0eDhNbNEREREJFtsZomIiIhIttjMEhEREZFssZklIiIiItliM0tEREREssVmloiIiIhki80sEREREckWm1kiIiIiki02s0RECqJSqXDo0CGpwyAiGjRsZomIjOTll1+GSqXq9oqOjpY6NCIi2RomdQBEREoSHR2NXbt2aW2ztLSUKBoiIvnjmVkiIiOytLSEm5ub1mvkyJEAOi4BSE9Px9y5c2FtbQ1vb2989NFHWvuXlJTgmWeegbW1NUaNGoVXXnkFTU1NWmsyMjIQGBgIS0tLuLu7IzExUevzu3fv4vnnn4eNjQ18fX1x+PBhzWfffPMN4uLi4OzsDGtra/j6+nZrvomITAmbWSIiE/L2229j4cKFuHTpEuLi4vDiiy+itLQUANDc3IyoqCiMHDkSBQUFOHDgAE6cOKHVrKanpyMhIQGvvPIKSkpKcPjwYfj4+Gh9R1paGhYtWoTLly/j2WefRVxcHO7du6f5/mvXruHYsWMoLS1Feno6nJycjJcAIqJ+UgkhhNRBEBEpwcsvv4y9e/fCyspKa/tbb72Ft956CyqVCq+++irS09M1n/3kJz/BlClT8P7772PHjh148803cefOHdja2gIAjh49ivnz56OyshKurq7w8PDA0qVLsW7dOp0xqFQq/P73v8c777wDoKNBHj58OI4dO4bo6GgsWLAATk5OyMjIMFAWiIgGF6+ZJSIyolmzZmk1qwDg6Oio+Tk0NFTrs9DQUBQXFwMASktLMXnyZE0jCwBPP/002tvbUVZWBpVKhcrKSkRERPQYQ1BQkOZnW1tb2Nvbo7a2FgCwYsUKLFy4EBcvXkRkZCRiYmIQFhY2oGMlIjIGNrNEREZka2vb7c/+g8Xa2rpP6ywsLLTeq1QqtLe3AwDmzp2LiooKHD16FFlZWYiIiEBCQgI2bdo06PESEQ0GXjNLRGRCzp492+39xIkTAQATJ07EpUuX0NzcrPk8Ly8PZmZm8PPzg52dHcaOHYvs7OxHisHZ2Rnx8fHYu3cv3nvvPfzpT396pN9HRGRIPDNLRGRELS0tqK6u1to2bNgwzU1WBw4cwLRp0zB9+nT85S9/wfnz5/HnP/8ZABAXF4eUlBTEx8cjNTUVdXV1eO2117BkyRK4uroCAFJTU/Hqq6/CxcUFc+fORWNjI/Ly8vDaa6/1Kb61a9di6tSpCAwMREtLC44cOaJppomITBGbWSIiI8rMzIS7u7vWNj8/P3zxxRcAOp40sG/fPqxcuRLu7u7429/+hoCAAACAjY0Njh8/jqSkJDz55JOwsbHBwoULsXnzZs3vio+Px4MHD7Blyxb85je/gZOTE1544YU+x6dWq7FmzRp8+eWXsLa2xowZM7Bv375BOHIiIsPg0wyIiEyESqXCwYMHERMTI3UoRESywWtmiYiIiEi22MwSERERkWzxmlkiIhPBq76IiPqPZ2aJiIiISLbYzBIRERGRbLGZJSIiIiLZYjNLRERERLLFZpaIiIiIZIvNLBERERHJFptZIiIiIpItNrNEREREJFv/D+B1id8UTy8VAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9 How do you perform inference on multiple images from a local folder using Faster RCNN and display the\n",
        "bounding boxes for each6"
      ],
      "metadata": {
        "id": "Vwz1uZssLJo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Path to your images folder\n",
        "image_folder = 'path/to/your/images_folder'\n",
        "\n",
        "# Load pretrained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# COCO classes\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
        "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
        "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog',\n",
        "    'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "# Define transformation\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "\n",
        "# Confidence threshold to filter weak detections\n",
        "threshold = 0.5\n",
        "\n",
        "# Load font for drawing labels (optional)\n",
        "font = ImageFont.load_default()\n",
        "\n",
        "# Iterate over images in folder\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Draw bounding boxes and labels\n",
        "for box, score, label_idx in zip(output['boxes'], output['scores'], output['labels']):\n",
        "\n",
        "    if score >= threshold:\n",
        "\n",
        "      x1, y1, x2, y2 = box\n",
        "      x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "      label = COCO_INSTANCE_CATEGORY_NAMES[label_idx]\n",
        "      draw.rectangle([(x1, y1), (x2, y2)], outline='red', width=3)\n",
        "      draw.text((x1, y1 - 10), f\"{label}: {score:.2f}\", fill='red', font=font)\n",
        "\n",
        "        # Display the image with detections\n",
        "      image.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "PISgDGGtLF-h",
        "outputId": "83886103-6b2a-4f4c-ee49-a06efd345772"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-695304cea453>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Draw bounding boxes and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 How do you visualize the confidence scores alongside the bounding boxes for detected objects using Faster\n",
        "RCNN6"
      ],
      "metadata": {
        "id": "jkYzk0SPMEyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "# Load pretrained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load and preprocess image\n",
        "image_path = 'path/to/image.jpg'\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "img_tensor = transform(image)\n",
        "\n",
        "# COCO class names\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
        "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
        "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog',\n",
        "    'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "threshold = 0.5  # Confidence threshold\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model([img_tensor])\n",
        "\n",
        "output = outputs[0]\n",
        "draw = ImageDraw.Draw(image)\n",
        "font = ImageFont.load_default()\n",
        "\n",
        "for box, score, label_idx in zip(output['boxes'], output['scores'], output['labels']):\n",
        "    if score >= threshold:\n",
        "        x1, y1, x2, y2 = box\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        label = COCO_INSTANCE_CATEGORY_NAMES[label_idx]\n",
        "        # Draw bounding box\n",
        "        draw.rectangle([(x1, y1), (x2, y2)], outline='red', width=3)\n",
        "        # Draw label + confidence score\n",
        "        text = f\"{label}: {score:.2f}\"\n",
        "        draw.text((x1, y1 - 10), text, fill='red', font=font)\n",
        "\n",
        "image.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "IYbbLYfqLrKC",
        "outputId": "116d02a7-e033-4180-f738-7472f0f9407d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path/to/image.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-99805931b3f8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load and preprocess image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/image.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/image.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12 = How can you save the inference results (with bounding boxes) as a new image after performing detection\n",
        "using YOLO?"
      ],
      "metadata": {
        "id": "bVdBKyhSMP2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLO model (YOLOv8 or YOLOv9 weights)\n",
        "model = YOLO('yolov8n.pt')  # or your custom weights\n",
        "\n",
        "# Run inference on image\n",
        "results = model('path/to/image.jpg')\n",
        "\n",
        "# results[0].plot() returns an image with bounding boxes drawn (as a NumPy array)\n",
        "annotated_img = results[0].plot()\n",
        "\n",
        "# Convert to PIL Image and save\n",
        "from PIL import Image\n",
        "im = Image.fromarray(annotated_img)\n",
        "im.save('output_with_boxes.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "JldpynnMMJfp",
        "outputId": "f47f5cdd-bf3c-4ca7-d00c-889eecdfcb90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "path/to/image.jpg does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b92b71f32216>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Run inference on image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# results[0].plot() returns an image with bounding boxes drawn (as a NumPy array)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_imgsz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, batch, vid_stride, buffer, channels)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImagesAndVideos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch, vid_stride, channels)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Define files as images or videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: path/to/image.jpg does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nk8t398wMUJm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}